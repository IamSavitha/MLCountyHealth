{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Uzm6WJhHqT",
        "outputId": "d7939431-01fb-449a-948f-0da35cee19c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOv8wlP7aQM2",
        "outputId": "bd8d5744-92c0-447c-ebfd-1a1eda9a1a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FOOD DESERT AND HEALTH RISK ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "STEP 0: DATA PREPARATION\n",
            "======================================================================\n",
            "\n",
            "[1/8] Loading data...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded: 2275 counties, 45 features\n",
            "\n",
            "[2/8] Fixing FIPS format...\n",
            "\n",
            "[3/8] Creating target variables...\n",
            "Three-class: Low<0.264, Medium=0.264-0.287, High>0.287\n",
            "Binary threshold: 38.7% obesity\n",
            "\n",
            "[4/8] Handling missing values...\n",
            "After cleaning: 2236 counties\n",
            "\n",
            "[5/8] Defining feature sets...\n",
            "Feature Set 1: 11 features\n",
            "Note: Removed health outcome indicators to avoid data leakage\n",
            "\n",
            "[6/8] Creating PCA features...\n",
            "PCA variance explained: 91.5%\n",
            "Feature Set 2 (PCA): 6 features\n",
            "Feature Set 3 (Simplified): 6 features\n",
            "\n",
            "[7/8] Splitting train/test sets...\n",
            "Train set: 1565 counties\n",
            "Test set: 671 counties\n",
            "\n",
            "[8/8] Saving prepared data...\n",
            "Data preparation complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Food Desert and Health Risk Analysis - Complete Pipeline\n",
        "Part 1: Imports and Data Preparation\n",
        "Run this in Google Colab\n",
        "\"\"\"\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    BaggingClassifier,\n",
        "    VotingClassifier,\n",
        "    StackingClassifier\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    accuracy_score, f1_score, cohen_kappa_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "import plotly.graph_objects as go\n",
        "import time\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FOOD DESERT AND HEALTH RISK ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 0: DATA PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nSTEP 0: DATA PREPARATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data (user must upload cleaned_health_data.csv first)\n",
        "print(\"\\n[1/8] Loading data...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_health_data.csv')\n",
        "print(f\"Loaded: {len(df)} counties, {len(df.columns)} features\")\n",
        "\n",
        "# Fix FIPS format\n",
        "print(\"\\n[2/8] Fixing FIPS format...\")\n",
        "df['FIPS'] = df['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Create target variables\n",
        "print(\"\\n[3/8] Creating target variables...\")\n",
        "\n",
        "# Three-class target\n",
        "risk_low = df['Health_Risk_Score'].quantile(0.33)\n",
        "risk_high = df['Health_Risk_Score'].quantile(0.67)\n",
        "df['Risk_Category_3Class'] = pd.cut(\n",
        "    df['Health_Risk_Score'],\n",
        "    bins=[-np.inf, risk_low, risk_high, np.inf],\n",
        "    labels=['Low', 'Medium', 'High']\n",
        ")\n",
        "\n",
        "# Binary target\n",
        "obesity_median = df['% Adults with Obesity'].median()\n",
        "df['Risk_Category_Binary'] = (df['% Adults with Obesity'] >= obesity_median).map({\n",
        "    True: 'High', False: 'Low'\n",
        "})\n",
        "\n",
        "print(f\"Three-class: Low<{risk_low:.3f}, Medium={risk_low:.3f}-{risk_high:.3f}, High>{risk_high:.3f}\")\n",
        "print(f\"Binary threshold: {obesity_median:.1f}% obesity\")\n",
        "\n",
        "# Handle missing values\n",
        "print(\"\\n[4/8] Handling missing values...\")\n",
        "key_columns = [\n",
        "    'FIPS', 'State', 'County',\n",
        "    'Risk_Category_3Class', 'Risk_Category_Binary',\n",
        "    'Food_Access_Barrier_Index', 'Food Environment Index',\n",
        "    '80th Percentile Income', '20th Percentile Income', 'Income Ratio',\n",
        "    '% Children in Poverty', '% Some College', '% Completed High School',\n",
        "    '% Uninsured', '% Rural', 'High_Income_Inequality',\n",
        "    '% Adults with Obesity', '% Adults with Diabetes'\n",
        "]\n",
        "\n",
        "df_clean = df.dropna(subset=key_columns)\n",
        "print(f\"After cleaning: {len(df_clean)} counties\")\n",
        "\n",
        "# Define features - REMOVED \"Average Number of Physically Unhealthy Days\"\n",
        "print(\"\\n[5/8] Defining feature sets...\")\n",
        "\n",
        "features_set1 = [\n",
        "    'Food_Access_Barrier_Index',\n",
        "    'Food Environment Index',\n",
        "    '80th Percentile Income',\n",
        "    '20th Percentile Income',\n",
        "    'Income Ratio',\n",
        "    '% Children in Poverty',\n",
        "    '% Some College',\n",
        "    '% Completed High School',\n",
        "    '% Uninsured',\n",
        "    '% Rural',\n",
        "    'High_Income_Inequality'\n",
        "]\n",
        "\n",
        "print(f\"Feature Set 1: {len(features_set1)} features\")\n",
        "print(\"Note: Removed health outcome indicators to avoid data leakage\")\n",
        "\n",
        "# PCA features\n",
        "print(\"\\n[6/8] Creating PCA features...\")\n",
        "socioeconomic_features = [\n",
        "    '80th Percentile Income',\n",
        "    '20th Percentile Income',\n",
        "    'Income Ratio',\n",
        "    '% Children in Poverty',\n",
        "    '% Some College',\n",
        "    '% Completed High School'\n",
        "]\n",
        "\n",
        "X_pca = df_clean[socioeconomic_features]\n",
        "scaler_pca = StandardScaler()\n",
        "X_scaled_pca = scaler_pca.fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "pca_components = pca.fit_transform(X_scaled_pca)\n",
        "\n",
        "df_clean['PC1'] = pca_components[:, 0]\n",
        "df_clean['PC2'] = pca_components[:, 1]\n",
        "df_clean['PC3'] = pca_components[:, 2]\n",
        "\n",
        "print(f\"PCA variance explained: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
        "\n",
        "features_set2 = [\n",
        "    'PC1', 'PC2', 'PC3',\n",
        "    'Food_Access_Barrier_Index',\n",
        "    'Food Environment Index',\n",
        "    '% Rural'\n",
        "]\n",
        "\n",
        "features_set3 = [\n",
        "    'Food_Access_Barrier_Index',\n",
        "    'Income Ratio',\n",
        "    '% Children in Poverty',\n",
        "    '% Completed High School',\n",
        "    '% Rural',\n",
        "    'High_Income_Inequality'\n",
        "]\n",
        "\n",
        "print(f\"Feature Set 2 (PCA): {len(features_set2)} features\")\n",
        "print(f\"Feature Set 3 (Simplified): {len(features_set3)} features\")\n",
        "\n",
        "# Prepare data\n",
        "print(\"\\n[7/8] Splitting train/test sets...\")\n",
        "X1 = df_clean[features_set1]\n",
        "X2 = df_clean[features_set2]\n",
        "X3 = df_clean[features_set3]\n",
        "y_3class = df_clean['Risk_Category_3Class']\n",
        "y_binary = df_clean['Risk_Category_Binary']\n",
        "\n",
        "# Three-class splits\n",
        "X1_train_3c, X1_test_3c, y_train_3c, y_test_3c = train_test_split(\n",
        "    X1, y_3class, test_size=0.3, random_state=42, stratify=y_3class\n",
        ")\n",
        "\n",
        "X2_train_3c, X2_test_3c, _, _ = train_test_split(\n",
        "    X2, y_3class, test_size=0.3, random_state=42, stratify=y_3class\n",
        ")\n",
        "\n",
        "X3_train_3c, X3_test_3c, _, _ = train_test_split(\n",
        "    X3, y_3class, test_size=0.3, random_state=42, stratify=y_3class\n",
        ")\n",
        "\n",
        "# Binary splits\n",
        "X1_train_bin, X1_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
        "    X1, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "X2_train_bin, X2_test_bin, _, _ = train_test_split(\n",
        "    X2, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "X3_train_bin, X3_test_bin, _, _ = train_test_split(\n",
        "    X3, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "print(f\"Train set: {len(X1_train_3c)} counties\")\n",
        "print(f\"Test set: {len(X1_test_3c)} counties\")\n",
        "\n",
        "# Save prepared data\n",
        "print(\"\\n[8/8] Saving prepared data...\")\n",
        "df_clean.to_csv('data_clean_final.csv', index=False)\n",
        "print(\"Data preparation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Part 2: Step 1 - Three-Class Classification with Gini Index Analysis\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: THREE-CLASS CLASSIFICATION + GINI INDEX\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: THREE-CLASS CLASSIFICATION + GINI INDEX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "step1_results = []\n",
        "\n",
        "feature_sets_3c = {\n",
        "    'Set1_Original': (X1_train_3c, X1_test_3c),\n",
        "    'Set2_PCA': (X2_train_3c, X2_test_3c),\n",
        "    'Set3_Simplified': (X3_train_3c, X3_test_3c)\n",
        "}\n",
        "\n",
        "print(\"\\n[1/4] Training models...\")\n",
        "\n",
        "for set_name, (X_tr, X_te) in feature_sets_3c.items():\n",
        "    print(f\"\\n{set_name} ({X_tr.shape[1]} features)...\")\n",
        "\n",
        "    # Random Forest\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    rf_model.fit(X_tr, y_train_3c)\n",
        "    rf_pred = rf_model.predict(X_te)\n",
        "    rf_proba = rf_model.predict_proba(X_te)\n",
        "\n",
        "    # Extra Trees\n",
        "    et_model = ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    et_model.fit(X_tr, y_train_3c)\n",
        "    et_pred = et_model.predict(X_te)\n",
        "    et_proba = et_model.predict_proba(X_te)\n",
        "\n",
        "    # Calculate metrics\n",
        "    y_test_bin_3c = label_binarize(y_test_3c, classes=['Low', 'Medium', 'High'])\n",
        "    rf_auc = roc_auc_score(y_test_bin_3c, rf_proba, average='weighted', multi_class='ovr')\n",
        "    et_auc = roc_auc_score(y_test_bin_3c, et_proba, average='weighted', multi_class='ovr')\n",
        "\n",
        "    step1_results.append({\n",
        "        'Feature_Set': set_name,\n",
        "        'Model': 'Random Forest',\n",
        "        'Accuracy': accuracy_score(y_test_3c, rf_pred),\n",
        "        'F1_Weighted': f1_score(y_test_3c, rf_pred, average='weighted'),\n",
        "        'F1_Macro': f1_score(y_test_3c, rf_pred, average='macro'),\n",
        "        'Cohens_Kappa': cohen_kappa_score(y_test_3c, rf_pred),\n",
        "        'ROC_AUC': rf_auc\n",
        "    })\n",
        "\n",
        "    step1_results.append({\n",
        "        'Feature_Set': set_name,\n",
        "        'Model': 'Extra Trees',\n",
        "        'Accuracy': accuracy_score(y_test_3c, et_pred),\n",
        "        'F1_Weighted': f1_score(y_test_3c, et_pred, average='weighted'),\n",
        "        'F1_Macro': f1_score(y_test_3c, et_pred, average='macro'),\n",
        "        'Cohens_Kappa': cohen_kappa_score(y_test_3c, et_pred),\n",
        "        'ROC_AUC': et_auc\n",
        "    })\n",
        "\n",
        "    if set_name == 'Set1_Original':\n",
        "        best_rf_3c = rf_model\n",
        "        best_et_3c = et_model\n",
        "        best_rf_pred_3c = rf_pred\n",
        "        best_et_pred_3c = et_pred\n",
        "\n",
        "# Save results\n",
        "step1_df = pd.DataFrame(step1_results)\n",
        "step1_df.to_csv('step1_model_comparison_results.csv', index=False)\n",
        "\n",
        "print(f\"\\nRandom Forest: {step1_df[(step1_df['Model']=='Random Forest') & (step1_df['Feature_Set']=='Set1_Original')]['Accuracy'].values[0]:.4f}\")\n",
        "print(f\"Extra Trees: {step1_df[(step1_df['Model']=='Extra Trees') & (step1_df['Feature_Set']=='Set1_Original')]['Accuracy'].values[0]:.4f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "print(\"\\n[2/4] Generating confusion matrices...\")\n",
        "cm_rf_3c = confusion_matrix(y_test_3c, best_rf_pred_3c, labels=['High', 'Low', 'Medium'])\n",
        "cm_et_3c = confusion_matrix(y_test_3c, best_et_pred_3c, labels=['High', 'Low', 'Medium'])\n",
        "\n",
        "np.savetxt('step1_confusion_matrix_rf.csv', cm_rf_3c, delimiter=',', fmt='%d')\n",
        "np.savetxt('step1_confusion_matrix_et.csv', cm_et_3c, delimiter=',', fmt='%d')\n",
        "\n",
        "# Gini Index Calculation\n",
        "print(\"\\n[3/4] Calculating Gini Index...\")\n",
        "\n",
        "def calculate_gini_index(y_true):\n",
        "    \"\"\"\n",
        "    Calculate Gini impurity for a label array\n",
        "    Gini = 1 - sum(p_i^2) where p_i is proportion of class i\n",
        "    Lower Gini = more pure classes\n",
        "    \"\"\"\n",
        "    value_counts = pd.Series(y_true).value_counts()\n",
        "    proportions = value_counts / len(y_true)\n",
        "    gini = 1 - (proportions ** 2).sum()\n",
        "    return gini\n",
        "\n",
        "# Calculate for three-class\n",
        "gini_3class_train = calculate_gini_index(y_train_3c)\n",
        "gini_3class_test = calculate_gini_index(y_test_3c)\n",
        "\n",
        "# Per-class distribution (more meaningful than per-class Gini)\n",
        "class_dist_3c = {}\n",
        "for cls in ['Low', 'Medium', 'High']:\n",
        "    count = (y_train_3c == cls).sum()\n",
        "    class_dist_3c[cls] = count / len(y_train_3c)\n",
        "\n",
        "# Calculate for binary (for comparison in Step 2)\n",
        "gini_binary_train = calculate_gini_index(y_train_bin)\n",
        "gini_binary_test = calculate_gini_index(y_test_bin)\n",
        "\n",
        "gini_results = {\n",
        "    'Classification_Type': ['Three-Class', 'Binary'],\n",
        "    'Gini_Index_Train': [gini_3class_train, gini_binary_train],\n",
        "    'Gini_Index_Test': [gini_3class_test, gini_binary_test],\n",
        "    'Interpretation': [\n",
        "        'Higher impurity - more class overlap',\n",
        "        'Lower impurity - clearer separation'\n",
        "    ]\n",
        "}\n",
        "\n",
        "gini_df = pd.DataFrame(gini_results)\n",
        "gini_df.to_csv('step1_gini_comparison.csv', index=False)\n",
        "\n",
        "print(f\"\\nGini Index Comparison:\")\n",
        "print(f\"  Three-Class: {gini_3class_train:.4f} (higher = more impure)\")\n",
        "print(f\"  Binary:      {gini_binary_train:.4f} (lower = more pure)\")\n",
        "print(f\"  Difference:  {gini_3class_train - gini_binary_train:.4f}\")\n",
        "\n",
        "print(\"\\nClass Distribution (Three-Class):\")\n",
        "for cls, pct in class_dist_3c.items():\n",
        "  print(f\"  {cls}: {pct:.2%} ({int(pct * len(y_train_3c))} samples)\")\n",
        "\n",
        "# Feature importance\n",
        "print(\"\\n[4/4] Saving feature importance...\")\n",
        "feature_names = X1_train_3c.columns.tolist()\n",
        "rf_importance = best_rf_3c.feature_importances_\n",
        "et_importance = best_et_3c.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'RF_Importance': rf_importance,\n",
        "    'ET_Importance': et_importance\n",
        "}).sort_values('RF_Importance', ascending=False)\n",
        "\n",
        "importance_df.to_csv('step1_feature_importance.csv', index=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "for idx, row in importance_df.head(5).iterrows():\n",
        "    print(f\"  {row['Feature']}: {row['RF_Importance']:.4f}\")\n",
        "\n",
        "print(\"\\nStep 1 Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tSqOMkZgupB",
        "outputId": "638b59da-2271-477f-974c-8852e3a9156d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: THREE-CLASS CLASSIFICATION + GINI INDEX\n",
            "======================================================================\n",
            "\n",
            "[1/4] Training models...\n",
            "\n",
            "Set1_Original (11 features)...\n",
            "\n",
            "Set2_PCA (6 features)...\n",
            "\n",
            "Set3_Simplified (6 features)...\n",
            "\n",
            "Random Forest: 0.5529\n",
            "Extra Trees: 0.5499\n",
            "\n",
            "[2/4] Generating confusion matrices...\n",
            "\n",
            "[3/4] Calculating Gini Index...\n",
            "\n",
            "Gini Index Comparison:\n",
            "  Three-Class: 0.6666 (higher = more impure)\n",
            "  Binary:      0.4999 (lower = more pure)\n",
            "  Difference:  0.1667\n",
            "\n",
            "Class Distribution (Three-Class):\n",
            "  Low: 32.97% (516 samples)\n",
            "  Medium: 33.87% (530 samples)\n",
            "  High: 33.16% (519 samples)\n",
            "\n",
            "[4/4] Saving feature importance...\n",
            "\n",
            "Top 5 Features (Random Forest):\n",
            "  % Completed High School: 0.1490\n",
            "  % Children in Poverty: 0.1162\n",
            "  Food_Access_Barrier_Index: 0.1114\n",
            "  20th Percentile Income: 0.1070\n",
            "  80th Percentile Income: 0.1043\n",
            "\n",
            "Step 1 Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Part 3: Step 2 - Binary Classification\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: BINARY CLASSIFICATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 2: BINARY CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "step2_results = []\n",
        "\n",
        "feature_sets_bin = {\n",
        "    'Set1_Original': (X1_train_bin, X1_test_bin),\n",
        "    'Set2_PCA': (X2_train_bin, X2_test_bin),\n",
        "    'Set3_Simplified': (X3_train_bin, X3_test_bin)\n",
        "}\n",
        "\n",
        "print(\"\\n[1/3] Training models...\")\n",
        "\n",
        "for set_name, (X_tr, X_te) in feature_sets_bin.items():\n",
        "    print(f\"\\n{set_name} ({X_tr.shape[1]} features)...\")\n",
        "\n",
        "    # Random Forest\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_model.fit(X_tr, y_train_bin)\n",
        "    rf_pred = rf_model.predict(X_te)\n",
        "    rf_proba = rf_model.predict_proba(X_te)\n",
        "\n",
        "    # Extra Trees\n",
        "    et_model = ExtraTreesClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    et_model.fit(X_tr, y_train_bin)\n",
        "    et_pred = et_model.predict(X_te)\n",
        "    et_proba = et_model.predict_proba(X_te)\n",
        "\n",
        "    # Calculate metrics\n",
        "    step2_results.append({\n",
        "        'Feature_Set': set_name,\n",
        "        'Model': 'Random Forest',\n",
        "        'Accuracy': accuracy_score(y_test_bin, rf_pred),\n",
        "        'F1_Score': f1_score(y_test_bin, rf_pred, pos_label='High'),\n",
        "        'Cohens_Kappa': cohen_kappa_score(y_test_bin, rf_pred),\n",
        "        'ROC_AUC': roc_auc_score(y_test_bin, rf_proba[:, 1])\n",
        "    })\n",
        "\n",
        "    step2_results.append({\n",
        "        'Feature_Set': set_name,\n",
        "        'Model': 'Extra Trees',\n",
        "        'Accuracy': accuracy_score(y_test_bin, et_pred),\n",
        "        'F1_Score': f1_score(y_test_bin, et_pred, pos_label='High'),\n",
        "        'Cohens_Kappa': cohen_kappa_score(y_test_bin, et_pred),\n",
        "        'ROC_AUC': roc_auc_score(y_test_bin, et_proba[:, 1])\n",
        "    })\n",
        "\n",
        "    if set_name == 'Set1_Original':\n",
        "        best_rf_bin = rf_model\n",
        "        best_et_bin = et_model\n",
        "        best_rf_pred_bin = rf_pred\n",
        "        best_et_pred_bin = et_pred\n",
        "\n",
        "# Save results\n",
        "step2_df = pd.DataFrame(step2_results)\n",
        "step2_df.to_csv('step2_model_comparison_binary.csv', index=False)\n",
        "\n",
        "rf_acc_bin = step2_df[(step2_df['Model']=='Random Forest') & (step2_df['Feature_Set']=='Set1_Original')]['Accuracy'].values[0]\n",
        "et_acc_bin = step2_df[(step2_df['Model']=='Extra Trees') & (step2_df['Feature_Set']=='Set1_Original')]['Accuracy'].values[0]\n",
        "\n",
        "print(f\"\\nRandom Forest: {rf_acc_bin:.4f}\")\n",
        "print(f\"Extra Trees: {et_acc_bin:.4f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "print(\"\\n[2/3] Generating confusion matrices...\")\n",
        "cm_rf_bin = confusion_matrix(y_test_bin, best_rf_pred_bin, labels=['High', 'Low'])\n",
        "cm_et_bin = confusion_matrix(y_test_bin, best_et_pred_bin, labels=['High', 'Low'])\n",
        "\n",
        "np.savetxt('step2_confusion_matrix_rf_binary.csv', cm_rf_bin, delimiter=',', fmt='%d')\n",
        "np.savetxt('step2_confusion_matrix_et_binary.csv', cm_et_bin, delimiter=',', fmt='%d')\n",
        "\n",
        "# Feature importance\n",
        "print(\"\\n[3/3] Saving feature importance...\")\n",
        "feature_names = X1_train_bin.columns.tolist()\n",
        "rf_importance = best_rf_bin.feature_importances_\n",
        "et_importance = best_et_bin.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'RF_Importance': rf_importance,\n",
        "    'ET_Importance': et_importance\n",
        "}).sort_values('RF_Importance', ascending=False)\n",
        "\n",
        "importance_df.to_csv('step2_feature_importance_binary.csv', index=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "for idx, row in importance_df.head(5).iterrows():\n",
        "    print(f\"  {row['Feature']}: {row['RF_Importance']:.4f}\")\n",
        "\n",
        "# Find Food Access rank\n",
        "food_row = importance_df[importance_df['Feature'] == 'Food_Access_Barrier_Index']\n",
        "if not food_row.empty:\n",
        "    food_rank = importance_df.index.get_loc(food_row.index[0]) + 1\n",
        "    food_importance = food_row['RF_Importance'].values[0]\n",
        "    print(f\"\\nFood_Access_Barrier_Index: Rank #{food_rank}, Importance {food_importance:.4f}\")\n",
        "\n",
        "print(\"\\nStep 2 Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "bBFKI1Cag2J9",
        "outputId": "b1f63846-062a-45e0-ab50-ece050bd91f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: BINARY CLASSIFICATION\n",
            "======================================================================\n",
            "\n",
            "[1/3] Training models...\n",
            "\n",
            "Set1_Original (11 features)...\n",
            "\n",
            "Set2_PCA (6 features)...\n",
            "\n",
            "Set3_Simplified (6 features)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3638775604.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0met_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0met_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0met_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Part 4: DBSCAN Noise Filtering (Fixed - No Scaling for RF/ET)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: DBSCAN NOISE FILTERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n[1/5] Scaling features for DBSCAN...\")\n",
        "scaler_dbscan = StandardScaler()\n",
        "X_train_scaled = scaler_dbscan.fit_transform(X1_train_bin)\n",
        "\n",
        "print(f\"Original train set: {len(X1_train_bin)} samples\")\n",
        "print(f\"Test set: {len(X1_test_bin)} samples\")\n",
        "\n",
        "print(\"\\n[2/5] Testing DBSCAN configurations...\")\n",
        "\n",
        "dbscan_results = []\n",
        "\n",
        "# Baseline (no filtering, no scaling)\n",
        "print(\"Baseline (no filtering)...\")\n",
        "rf_baseline = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=15,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_baseline.fit(X1_train_bin, y_train_bin)\n",
        "pred_baseline = rf_baseline.predict(X1_test_bin)\n",
        "proba_baseline = rf_baseline.predict_proba(X1_test_bin)\n",
        "\n",
        "acc_baseline = accuracy_score(y_test_bin, pred_baseline)\n",
        "f1_baseline = f1_score(y_test_bin, pred_baseline, pos_label='High')\n",
        "auc_baseline = roc_auc_score(y_test_bin, proba_baseline[:, 1])\n",
        "\n",
        "print(f\"  Accuracy: {acc_baseline:.4f}\")\n",
        "print(f\"  F1-Score: {f1_baseline:.4f}\")\n",
        "print(f\"  ROC-AUC: {auc_baseline:.4f}\")\n",
        "\n",
        "dbscan_results.append({\n",
        "    'Method': 'Baseline',\n",
        "    'Eps': 'N/A',\n",
        "    'Min_Samples': 'N/A',\n",
        "    'Train_Size': len(X1_train_bin),\n",
        "    'Noise_Removed': 0,\n",
        "    'Noise_Pct': 0.0,\n",
        "    'Accuracy': acc_baseline,\n",
        "    'F1_Score': f1_baseline,\n",
        "    'ROC_AUC': auc_baseline\n",
        "})\n",
        "\n",
        "# Test DBSCAN configurations (use scaled data to find noise)\n",
        "eps_values = [0.5, 1.0, 1.5, 2.0, 2.5]\n",
        "min_samples_values = [5, 10, 15]\n",
        "\n",
        "best_acc = acc_baseline\n",
        "best_config = None\n",
        "best_X_clean = None\n",
        "best_y_clean = None\n",
        "best_clean_mask = None\n",
        "\n",
        "print(\"\\nTesting DBSCAN configurations...\")\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        # Use scaled data for DBSCAN\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
        "        cluster_labels = dbscan.fit_predict(X_train_scaled)\n",
        "\n",
        "        noise_mask = cluster_labels == -1\n",
        "        clean_mask = cluster_labels != -1\n",
        "\n",
        "        noise_count = noise_mask.sum()\n",
        "        noise_pct = noise_count / len(X1_train_bin) * 100\n",
        "\n",
        "        if noise_count == 0 or noise_count == len(X1_train_bin):\n",
        "            continue\n",
        "\n",
        "        # Train on clean data (ORIGINAL unscaled data)\n",
        "        X_train_clean = X1_train_bin.values[clean_mask]\n",
        "        y_train_clean = y_train_bin.values[clean_mask]\n",
        "\n",
        "        rf_clean = RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=15,\n",
        "            min_samples_split=10,\n",
        "            min_samples_leaf=5,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        rf_clean.fit(X_train_clean, y_train_clean)\n",
        "        pred_clean = rf_clean.predict(X1_test_bin)\n",
        "        proba_clean = rf_clean.predict_proba(X1_test_bin)\n",
        "\n",
        "        acc_clean = accuracy_score(y_test_bin, pred_clean)\n",
        "        f1_clean = f1_score(y_test_bin, pred_clean, pos_label='High')\n",
        "        auc_clean = roc_auc_score(y_test_bin, proba_clean[:, 1])\n",
        "\n",
        "        dbscan_results.append({\n",
        "            'Method': 'DBSCAN',\n",
        "            'Eps': eps,\n",
        "            'Min_Samples': min_samples,\n",
        "            'Train_Size': len(X_train_clean),\n",
        "            'Noise_Removed': noise_count,\n",
        "            'Noise_Pct': noise_pct,\n",
        "            'Accuracy': acc_clean,\n",
        "            'F1_Score': f1_clean,\n",
        "            'ROC_AUC': auc_clean\n",
        "        })\n",
        "\n",
        "        if acc_clean > best_acc:\n",
        "            best_acc = acc_clean\n",
        "            best_config = (eps, min_samples)\n",
        "            best_X_clean = X_train_clean\n",
        "            best_y_clean = y_train_clean\n",
        "            best_clean_mask = clean_mask\n",
        "\n",
        "# Save DBSCAN results\n",
        "dbscan_df = pd.DataFrame(dbscan_results)\n",
        "dbscan_df = dbscan_df.sort_values('Accuracy', ascending=False)\n",
        "dbscan_df.to_csv('step3_dbscan_filtering_results.csv', index=False)\n",
        "\n",
        "print(\"\\n[3/5] Best DBSCAN configuration:\")\n",
        "if best_config is not None:\n",
        "    print(f\"  Eps: {best_config[0]}\")\n",
        "    print(f\"  Min_Samples: {best_config[1]}\")\n",
        "    print(f\"  Accuracy: {best_acc:.4f}\")\n",
        "    print(f\"  Improvement: {best_acc - acc_baseline:+.4f} ({(best_acc - acc_baseline)*100:+.2f}%)\")\n",
        "\n",
        "    # Save best cleaned data\n",
        "    best_X_clean_df = pd.DataFrame(best_X_clean, columns=X1_train_bin.columns)\n",
        "    best_y_clean_df = pd.DataFrame(best_y_clean, columns=['Risk_Category_Binary'])\n",
        "\n",
        "    best_X_clean_df.to_csv('X1_train_dbscan_cleaned.csv', index=False)\n",
        "    best_y_clean_df.to_csv('y_train_dbscan_cleaned.csv', index=False)\n",
        "\n",
        "    print(\"\\nBest cleaned data saved\")\n",
        "else:\n",
        "    print(\"  No improvement found\")\n",
        "    best_X_clean = X1_train_bin.values\n",
        "    best_y_clean = y_train_bin.values\n",
        "\n",
        "print(\"\\n[4/5] Training final models with best configuration...\")\n",
        "\n",
        "# Random Forest\n",
        "rf_final = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=15,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_final.fit(best_X_clean, best_y_clean)\n",
        "rf_pred = rf_final.predict(X1_test_bin)\n",
        "rf_proba = rf_final.predict_proba(X1_test_bin)\n",
        "\n",
        "rf_acc = accuracy_score(y_test_bin, rf_pred)\n",
        "rf_f1 = f1_score(y_test_bin, rf_pred, pos_label='High')\n",
        "rf_auc = roc_auc_score(y_test_bin, rf_proba[:, 1])\n",
        "\n",
        "# Extra Trees\n",
        "et_final = ExtraTreesClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=15,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "et_final.fit(best_X_clean, best_y_clean)\n",
        "et_pred = et_final.predict(X1_test_bin)\n",
        "et_proba = et_final.predict_proba(X1_test_bin)\n",
        "\n",
        "et_acc = accuracy_score(y_test_bin, et_pred)\n",
        "et_f1 = f1_score(y_test_bin, et_pred, pos_label='High')\n",
        "et_auc = roc_auc_score(y_test_bin, et_proba[:, 1])\n",
        "\n",
        "print(f\"\\nRandom Forest:\")\n",
        "print(f\"  Accuracy: {rf_acc:.4f}\")\n",
        "print(f\"  F1-Score: {rf_f1:.4f}\")\n",
        "print(f\"  ROC-AUC: {rf_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nExtra Trees:\")\n",
        "print(f\"  Accuracy: {et_acc:.4f}\")\n",
        "print(f\"  F1-Score: {et_f1:.4f}\")\n",
        "print(f\"  ROC-AUC: {et_auc:.4f}\")\n",
        "\n",
        "# Save final results\n",
        "final_results_dbscan = pd.DataFrame([\n",
        "    {\n",
        "        'Model': 'Random Forest',\n",
        "        'Train_Samples': len(best_X_clean),\n",
        "        'Accuracy': rf_acc,\n",
        "        'F1_Score': rf_f1,\n",
        "        'ROC_AUC': rf_auc\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Extra Trees',\n",
        "        'Train_Samples': len(best_X_clean),\n",
        "        'Accuracy': et_acc,\n",
        "        'F1_Score': et_f1,\n",
        "        'ROC_AUC': et_auc\n",
        "    }\n",
        "])\n",
        "final_results_dbscan.to_csv('step3_model_results_dbscan.csv', index=False)\n",
        "\n",
        "# Confusion matrices\n",
        "cm_rf_dbscan = confusion_matrix(y_test_bin, rf_pred, labels=['High', 'Low'])\n",
        "cm_et_dbscan = confusion_matrix(y_test_bin, et_pred, labels=['High', 'Low'])\n",
        "\n",
        "np.savetxt('step3_confusion_matrix_rf.csv', cm_rf_dbscan, delimiter=',', fmt='%d')\n",
        "np.savetxt('step3_confusion_matrix_et.csv', cm_et_dbscan, delimiter=',', fmt='%d')\n",
        "\n",
        "print(\"\\n[5/5] Generating DBSCAN scatter plot...\")\n",
        "\n",
        "# Generate scatter plot\n",
        "if best_config is not None and best_clean_mask is not None:\n",
        "    # Use PCA for 2D visualization\n",
        "    pca_vis = PCA(n_components=2)\n",
        "    X_pca_vis = pca_vis.fit_transform(X_train_scaled)\n",
        "\n",
        "    var_explained = pca_vis.explained_variance_ratio_.sum() * 100\n",
        "\n",
        "    # Create scatter plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Retained points (green)\n",
        "    plt.scatter(X_pca_vis[best_clean_mask, 0], X_pca_vis[best_clean_mask, 1],\n",
        "                c='#27ae60', s=30, alpha=0.6,\n",
        "                label=f'Retained: {best_clean_mask.sum()} samples',\n",
        "                edgecolors='none')\n",
        "\n",
        "    # Noise points (gray X)\n",
        "    noise_mask_final = ~best_clean_mask\n",
        "    plt.scatter(X_pca_vis[noise_mask_final, 0], X_pca_vis[noise_mask_final, 1],\n",
        "                c='#95a5a6', s=60, alpha=0.8, marker='x', linewidths=2,\n",
        "                label=f'Filtered: {noise_mask_final.sum()} samples')\n",
        "\n",
        "    plt.xlabel(f'PC1 ({pca_vis.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
        "    plt.ylabel(f'PC2 ({pca_vis.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
        "    plt.title(f'DBSCAN Noise Detection (2D PCA, {var_explained:.1f}% variance)', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='upper right', fontsize=11, framealpha=0.9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig('step3_dbscan_scatter_plot.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"  Scatter plot saved: step3_dbscan_scatter_plot.png\")\n",
        "else:\n",
        "    print(\"  Skipped scatter plot (no improvement)\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance_dbscan = pd.DataFrame({\n",
        "    'Feature': X1_train_bin.columns,\n",
        "    'RF_Importance': rf_final.feature_importances_,\n",
        "    'ET_Importance': et_final.feature_importances_\n",
        "}).sort_values('RF_Importance', ascending=False)\n",
        "\n",
        "feature_importance_dbscan.to_csv('step3_feature_importance.csv', index=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "for idx, row in feature_importance_dbscan.head(5).iterrows():\n",
        "    print(f\"  {row['Feature']}: {row['RF_Importance']:.4f}\")\n",
        "\n",
        "print(\"\\nStep 3 Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGnBKuQxljUL",
        "outputId": "0efbfa36-44ac-48ab-f967-75854d3c3cad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: DBSCAN NOISE FILTERING\n",
            "======================================================================\n",
            "\n",
            "[1/5] Scaling features for DBSCAN...\n",
            "Original train set: 1565 samples\n",
            "Test set: 671 samples\n",
            "\n",
            "[2/5] Testing DBSCAN configurations...\n",
            "Baseline (no filtering)...\n",
            "  Accuracy: 0.6602\n",
            "  F1-Score: 0.6597\n",
            "  ROC-AUC: 0.7340\n",
            "\n",
            "Testing DBSCAN configurations...\n",
            "\n",
            "[3/5] Best DBSCAN configuration:\n",
            "  Eps: 2.0\n",
            "  Min_Samples: 10\n",
            "  Accuracy: 0.6677\n",
            "  Improvement: +0.0075 (+0.75%)\n",
            "\n",
            "Best cleaned data saved\n",
            "\n",
            "[4/5] Training final models with best configuration...\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy: 0.6677\n",
            "  F1-Score: 0.6686\n",
            "  ROC-AUC: 0.7340\n",
            "\n",
            "Extra Trees:\n",
            "  Accuracy: 0.6587\n",
            "  F1-Score: 0.6359\n",
            "  ROC-AUC: 0.7339\n",
            "\n",
            "[5/5] Generating DBSCAN scatter plot...\n",
            "  Scatter plot saved: step3_dbscan_scatter_plot.png\n",
            "\n",
            "Top 5 Features (Random Forest):\n",
            "  % Completed High School: 0.1473\n",
            "  80th Percentile Income: 0.1277\n",
            "  Food_Access_Barrier_Index: 0.1221\n",
            "  % Children in Poverty: 0.1135\n",
            "  % Some College: 0.1024\n",
            "\n",
            "Step 3 Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Part 5: Ensemble Methods Comparison\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 4: ENSEMBLE METHODS COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n[1/4] Loading DBSCAN-cleaned data...\")\n",
        "try:\n",
        "    X_train_clean = pd.read_csv('X1_train_dbscan_cleaned.csv')\n",
        "    y_train_clean = pd.read_csv('y_train_dbscan_cleaned.csv')['Risk_Category_Binary']\n",
        "    print(f\"  Loaded DBSCAN-cleaned data: {len(X_train_clean)} samples\")\n",
        "except:\n",
        "    print(\"  DBSCAN-cleaned data not found, using original data\")\n",
        "    X_train_clean = X1_train_bin\n",
        "    y_train_clean = y_train_bin\n",
        "\n",
        "# Split for ensemble validation\n",
        "X_train_ens, X_test_ens, y_train_ens, y_test_ens = train_test_split(\n",
        "    X_train_clean, y_train_clean, test_size=0.3, random_state=42, stratify=y_train_clean\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_ens = StandardScaler()\n",
        "X_train_ens_scaled = scaler_ens.fit_transform(X_train_ens)\n",
        "X_test_ens_scaled = scaler_ens.transform(X_test_ens)\n",
        "\n",
        "print(f\"  Ensemble train: {len(X_train_ens)} samples\")\n",
        "print(f\"  Ensemble test: {len(X_test_ens)} samples\")\n",
        "\n",
        "ensemble_results = []\n",
        "\n",
        "# Helper function for metrics\n",
        "def calculate_metrics(y_true, y_pred, y_proba, model_name):\n",
        "    return {\n",
        "        'Method': model_name,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1_Score': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'ROC_AUC': roc_auc_score(y_true, y_proba[:, 1])\n",
        "    }\n",
        "\n",
        "print(\"\\n[2/4] Training ensemble methods...\")\n",
        "\n",
        "# Random Forest (Baseline)\n",
        "print(\"  Random Forest (Baseline)...\")\n",
        "rf_ens = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_ens.fit(X_train_ens_scaled, y_train_ens)\n",
        "rf_pred_ens = rf_ens.predict(X_test_ens_scaled)\n",
        "rf_proba_ens = rf_ens.predict_proba(X_test_ens_scaled)\n",
        "ensemble_results.append(calculate_metrics(y_test_ens, rf_pred_ens, rf_proba_ens, 'Random Forest'))\n",
        "\n",
        "# Bagging\n",
        "print(\"  Bagging...\")\n",
        "base_estimator = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    max_samples=0.8,\n",
        "    max_features=0.8,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bagging.fit(X_train_ens_scaled, y_train_ens)\n",
        "bag_pred = bagging.predict(X_test_ens_scaled)\n",
        "bag_proba = bagging.predict_proba(X_test_ens_scaled)\n",
        "ensemble_results.append(calculate_metrics(y_test_ens, bag_pred, bag_proba, 'Bagging'))\n",
        "\n",
        "# Gradient Boosting\n",
        "print(\"  Gradient Boosting...\")\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "gb.fit(X_train_ens_scaled, y_train_ens)\n",
        "gb_pred = gb.predict(X_test_ens_scaled)\n",
        "gb_proba = gb.predict_proba(X_test_ens_scaled)\n",
        "ensemble_results.append(calculate_metrics(y_test_ens, gb_pred, gb_proba, 'Gradient Boosting'))\n",
        "\n",
        "# Voting Classifier\n",
        "print(\"  Voting Classifier...\")\n",
        "rf_vote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "et_vote = ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "gb_vote = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_vote),\n",
        "        ('et', et_vote),\n",
        "        ('gb', gb_vote)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "voting.fit(X_train_ens_scaled, y_train_ens)\n",
        "vote_pred = voting.predict(X_test_ens_scaled)\n",
        "vote_proba = voting.predict_proba(X_test_ens_scaled)\n",
        "ensemble_results.append(calculate_metrics(y_test_ens, vote_pred, vote_proba, 'Voting (Soft)'))\n",
        "\n",
        "# Stacking\n",
        "print(\"  Stacking Classifier...\")\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
        "    ('et', ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "stacking = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "stacking.fit(X_train_ens_scaled, y_train_ens)\n",
        "stack_pred = stacking.predict(X_test_ens_scaled)\n",
        "stack_proba = stacking.predict_proba(X_test_ens_scaled)\n",
        "ensemble_results.append(calculate_metrics(y_test_ens, stack_pred, stack_proba, 'Stacking'))\n",
        "\n",
        "print(\"\\n[3/4] Saving results...\")\n",
        "\n",
        "# Save results\n",
        "ensemble_df = pd.DataFrame(ensemble_results)\n",
        "ensemble_df = ensemble_df.sort_values('Accuracy', ascending=False)\n",
        "ensemble_df.to_csv('step4_ensemble_comparison.csv', index=False)\n",
        "\n",
        "print(\"\\nEnsemble Methods Results:\")\n",
        "print(ensemble_df.to_string(index=False))\n",
        "\n",
        "# Best model\n",
        "best_ensemble = ensemble_df.iloc[0]\n",
        "print(f\"\\nBest Method: {best_ensemble['Method']}\")\n",
        "print(f\"  Accuracy: {best_ensemble['Accuracy']:.4f}\")\n",
        "print(f\"  F1-Score: {best_ensemble['F1_Score']:.4f}\")\n",
        "print(f\"  ROC-AUC: {best_ensemble['ROC_AUC']:.4f}\")\n",
        "\n",
        "print(\"\\n[4/4] Generating confusion matrices for best method...\")\n",
        "\n",
        "# Generate confusion matrix for best method\n",
        "if best_ensemble['Method'] == 'Voting (Soft)':\n",
        "    best_pred = vote_pred\n",
        "elif best_ensemble['Method'] == 'Stacking':\n",
        "    best_pred = stack_pred\n",
        "elif best_ensemble['Method'] == 'Gradient Boosting':\n",
        "    best_pred = gb_pred\n",
        "elif best_ensemble['Method'] == 'Bagging':\n",
        "    best_pred = bag_pred\n",
        "else:\n",
        "    best_pred = rf_pred_ens\n",
        "\n",
        "cm_ensemble = confusion_matrix(y_test_ens, best_pred, labels=['High', 'Low'])\n",
        "np.savetxt('step4_confusion_matrix_ensemble.csv', cm_ensemble, delimiter=',', fmt='%d')\n",
        "\n",
        "print(\"\\nConfusion Matrix (Best Ensemble):\")\n",
        "print(f\"         Predicted\")\n",
        "print(f\"         High  Low\")\n",
        "print(f\"Actual High  {cm_ensemble[0,0]:4d} {cm_ensemble[0,1]:4d}\")\n",
        "print(f\"       Low   {cm_ensemble[1,0]:4d} {cm_ensemble[1,1]:4d}\")\n",
        "\n",
        "print(\"\\nStep 4 Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm-RG5cVo5Ln",
        "outputId": "8cebed66-deb7-4225-e29b-56426db52222"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: ENSEMBLE METHODS COMPARISON\n",
            "======================================================================\n",
            "\n",
            "[1/4] Loading DBSCAN-cleaned data...\n",
            "  Loaded DBSCAN-cleaned data: 1502 samples\n",
            "  Ensemble train: 1051 samples\n",
            "  Ensemble test: 451 samples\n",
            "\n",
            "[2/4] Training ensemble methods...\n",
            "  Random Forest (Baseline)...\n",
            "  Bagging...\n",
            "  Gradient Boosting...\n",
            "  Voting Classifier...\n",
            "  Stacking Classifier...\n",
            "\n",
            "[3/4] Saving results...\n",
            "\n",
            "Ensemble Methods Results:\n",
            "           Method  Accuracy  F1_Score  ROC_AUC\n",
            "         Stacking  0.691796  0.690976 0.760671\n",
            "    Voting (Soft)  0.691796  0.690827 0.759452\n",
            "    Random Forest  0.689579  0.689182 0.752764\n",
            "          Bagging  0.689579  0.688679 0.755537\n",
            "Gradient Boosting  0.678492  0.678464 0.735060\n",
            "\n",
            "Best Method: Stacking\n",
            "  Accuracy: 0.6918\n",
            "  F1-Score: 0.6910\n",
            "  ROC-AUC: 0.7607\n",
            "\n",
            "[4/4] Generating confusion matrices for best method...\n",
            "\n",
            "Confusion Matrix (Best Ensemble):\n",
            "         Predicted\n",
            "         High  Low\n",
            "Actual High   146   83\n",
            "       Low     56  166\n",
            "\n",
            "Step 4 Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR7cNv4U2OX0",
        "outputId": "7800e661-2f12-438f-9e1e-52c7f7cddf6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.9Gi       8.0Gi       2.0Mi       2.7Gi        10Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
        "for f in sorted(csv_files):\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SWJarxK4TJn",
        "outputId": "2dea08f8-c3c5-44cc-d680-c504b1e4b21d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1_train_dbscan_cleaned.csv\n",
            "data_clean_final.csv\n",
            "step1_confusion_matrix_et.csv\n",
            "step1_confusion_matrix_rf.csv\n",
            "step1_feature_importance.csv\n",
            "step1_gini_comparison.csv\n",
            "step1_model_comparison_results.csv\n",
            "step2_confusion_matrix_et_binary.csv\n",
            "step2_confusion_matrix_rf_binary.csv\n",
            "step2_feature_importance_binary.csv\n",
            "step2_model_comparison_binary.csv\n",
            "step3_confusion_matrix_et.csv\n",
            "step3_confusion_matrix_rf.csv\n",
            "step3_dbscan_filtering_results.csv\n",
            "step3_feature_importance.csv\n",
            "step3_model_results_dbscan.csv\n",
            "step4_confusion_matrix_ensemble.csv\n",
            "step4_ensemble_comparison.csv\n",
            "y_train_dbscan_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "gini = pd.read_csv('step1_gini_comparison.csv')\n",
        "print(gini.columns.tolist())\n",
        "print(gini)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI3EfrKc40co",
        "outputId": "094c2926-8e08-44f3-d373-7707b63dc295"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Classification_Type', 'Gini_Index_Train', 'Gini_Index_Test', 'Interpretation']\n",
            "  Classification_Type  Gini_Index_Train  Gini_Index_Test  \\\n",
            "0         Three-Class          0.666622         0.666603   \n",
            "1              Binary          0.499892         0.499866   \n",
            "\n",
            "                         Interpretation  \n",
            "0  Higher impurity - more class overlap  \n",
            "1   Lower impurity - clearer separation  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"UNIFIED DASHBOARD GENERATOR (COLAB VERSION)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ==================== LOAD ALL DATA ====================\n",
        "print(\"\\n[1/10] Loading all result files...\")\n",
        "\n",
        "try:\n",
        "    # Three-class results (Step 1)\n",
        "    three_class_df = pd.read_csv('step1_model_comparison_results.csv')\n",
        "    cm_rf_three = pd.read_csv('step1_confusion_matrix_rf.csv', header=None).values\n",
        "    cm_et_three = pd.read_csv('step1_confusion_matrix_et.csv', header=None).values\n",
        "\n",
        "    # Binary results (Step 2)\n",
        "    binary_df = pd.read_csv('step2_model_comparison_binary.csv')\n",
        "    cm_rf_binary = pd.read_csv('step2_confusion_matrix_rf_binary.csv', header=None).values\n",
        "    cm_et_binary = pd.read_csv('step2_confusion_matrix_et_binary.csv', header=None).values\n",
        "\n",
        "    # DBSCAN results (Step 3)\n",
        "    dbscan_df = pd.read_csv('step3_model_results_dbscan.csv')\n",
        "    cm_rf_dbscan = pd.read_csv('step3_confusion_matrix_rf.csv', header=None).values\n",
        "    cm_et_dbscan = pd.read_csv('step3_confusion_matrix_et.csv', header=None).values\n",
        "\n",
        "    # Ensemble results (Step 4)\n",
        "    ensemble_df = pd.read_csv('step4_ensemble_comparison.csv')\n",
        "\n",
        "    # Feature importance from DBSCAN (Step 3)\n",
        "    feature_importance = pd.read_csv('step3_feature_importance.csv')\n",
        "\n",
        "    print(\"  All CSV files loaded successfully\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"  Error: Missing file {e.filename}\")\n",
        "    print(\"  Please ensure all Parts (1-5) have been run successfully\")\n",
        "    raise\n",
        "\n",
        "# ==================== CALCULATE GINI INDEX ====================\n",
        "print(\"\\n[2/10] Calculating Gini Index for class purity comparison...\")\n",
        "\n",
        "def calculate_gini(y):\n",
        "    \"\"\"Calculate Gini impurity for a set of labels\"\"\"\n",
        "    if len(y) == 0:\n",
        "        return 0\n",
        "    if isinstance(y[0], str):\n",
        "        unique_vals = list(set(y))\n",
        "        y_encoded = [unique_vals.index(val) for val in y]\n",
        "    else:\n",
        "        y_encoded = y\n",
        "    counts = np.bincount(y_encoded)\n",
        "    probabilities = counts / len(y_encoded)\n",
        "    gini = 1 - np.sum(probabilities ** 2)\n",
        "    return gini\n",
        "\n",
        "# Try to load Gini comparison if available\n",
        "try:\n",
        "    gini_comparison = pd.read_csv('step1_gini_comparison.csv')\n",
        "    gini_comparison = gini_comparison.rename(columns={\n",
        "        'Classification_Type': 'Classification',\n",
        "        'Gini_Index_Train': 'Gini Index'\n",
        "    })\n",
        "    print(f\"  Three-Class Gini: {gini_comparison.iloc[0]['Gini Index']:.4f}\")\n",
        "    print(f\"  Binary Gini: {gini_comparison.iloc[1]['Gini Index']:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"  Warning: Error loading Gini comparison: {e}\")\n",
        "    gini_comparison = None\n",
        "\n",
        "# ==================== EXTRACT KEY METRICS ====================\n",
        "print(\"\\n[3/10] Extracting key metrics...\")\n",
        "\n",
        "# Three-class (Set1_Original)\n",
        "rf_three = three_class_df[(three_class_df['Feature_Set']=='Set1_Original') &\n",
        "                           (three_class_df['Model']=='Random Forest')].iloc[0]\n",
        "et_three = three_class_df[(three_class_df['Feature_Set']=='Set1_Original') &\n",
        "                           (three_class_df['Model']=='Extra Trees')].iloc[0]\n",
        "\n",
        "# Binary\n",
        "rf_binary = binary_df[binary_df['Model']=='Random Forest'].iloc[0]\n",
        "et_binary = binary_df[binary_df['Model']=='Extra Trees'].iloc[0]\n",
        "\n",
        "# DBSCAN\n",
        "rf_dbscan = dbscan_df[dbscan_df['Model']=='Random Forest'].iloc[0]\n",
        "et_dbscan = dbscan_df[dbscan_df['Model']=='Extra Trees'].iloc[0]\n",
        "\n",
        "# Best ensemble\n",
        "best_ensemble = ensemble_df.iloc[0]\n",
        "\n",
        "# Food desert importance (from DBSCAN step)\n",
        "food_feature = feature_importance[feature_importance['Feature']=='Food_Access_Barrier_Index'].iloc[0]\n",
        "food_rank = feature_importance.index[feature_importance['Feature']=='Food_Access_Barrier_Index'][0] + 1\n",
        "food_importance_rf = food_feature['RF_Importance']  # Changed from RF_Tuned_Importance\n",
        "\n",
        "print(f\"  Best accuracy: {best_ensemble['Accuracy']:.4f}\")\n",
        "print(f\"  Food Desert rank: #{food_rank}\")\n",
        "print(f\"  Food Desert importance: {food_importance_rf*100:.2f}%\")\n",
        "\n",
        "# ==================== CREATE VISUALIZATIONS ====================\n",
        "print(\"\\n[4/10] Creating visualizations...\")\n",
        "\n",
        "# Figure 1: Model Evolution Chart\n",
        "stages = ['Three-Class', 'Binary', 'DBSCAN', 'Ensemble']\n",
        "rf_scores = [\n",
        "    rf_three['Accuracy'],\n",
        "    rf_binary['Accuracy'],\n",
        "    rf_dbscan['Accuracy'],\n",
        "    best_ensemble['Accuracy'] if 'Random Forest' in best_ensemble['Method'] or 'Voting' in best_ensemble['Method'] else rf_dbscan['Accuracy']\n",
        "]\n",
        "et_scores = [\n",
        "    et_three['Accuracy'],\n",
        "    et_binary['Accuracy'],\n",
        "    et_dbscan['Accuracy'],\n",
        "    best_ensemble['Accuracy'] if 'Extra Trees' in best_ensemble['Method'] else et_dbscan['Accuracy']\n",
        "]\n",
        "\n",
        "fig1 = go.Figure()\n",
        "fig1.add_trace(go.Scatter(\n",
        "    x=stages, y=rf_scores,\n",
        "    mode='lines+markers+text',\n",
        "    name='Random Forest',\n",
        "    line=dict(color='#2E86AB', width=3),\n",
        "    marker=dict(size=10),\n",
        "    text=[f'{v:.1%}' for v in rf_scores],\n",
        "    textposition='top center'\n",
        "))\n",
        "fig1.add_trace(go.Scatter(\n",
        "    x=stages, y=et_scores,\n",
        "    mode='lines+markers+text',\n",
        "    name='Extra Trees',\n",
        "    line=dict(color='#A23B72', width=3),\n",
        "    marker=dict(size=10),\n",
        "    text=[f'{v:.1%}' for v in et_scores],\n",
        "    textposition='bottom center'\n",
        "))\n",
        "fig1.update_layout(\n",
        "    title='Model Performance Evolution',\n",
        "    xaxis_title='Optimization Stage',\n",
        "    yaxis_title='Accuracy',\n",
        "    height=450,\n",
        "    hovermode='x unified',\n",
        "    yaxis=dict(range=[0.5, 0.75])\n",
        ")\n",
        "fig1_html = fig1.to_html(include_plotlyjs='cdn', div_id='fig1')\n",
        "\n",
        "# Figure 2: Confusion Matrix HTML Tables\n",
        "def cm_to_html_table(cm, labels):\n",
        "    \"\"\"Convert confusion matrix to HTML table\"\"\"\n",
        "    n = len(labels)\n",
        "    html = '<table class=\"cm-table\"><thead><tr><th></th>'\n",
        "    for label in labels:\n",
        "        html += f'<th>Pred {label}</th>'\n",
        "    html += '</tr></thead><tbody>'\n",
        "    for i, label in enumerate(labels):\n",
        "        html += f'<tr><th>True {label}</th>'\n",
        "        for j in range(n):\n",
        "            html += f'<td>{cm[i,j]}</td>'\n",
        "        html += '</tr>'\n",
        "    html += '</tbody></table>'\n",
        "    return html\n",
        "\n",
        "cm_rf_three_html = cm_to_html_table(cm_rf_three, ['High', 'Low', 'Medium'])\n",
        "cm_et_three_html = cm_to_html_table(cm_et_three, ['High', 'Low', 'Medium'])\n",
        "cm_rf_binary_html = cm_to_html_table(cm_rf_binary, ['High', 'Low'])\n",
        "cm_et_binary_html = cm_to_html_table(cm_et_binary, ['High', 'Low'])\n",
        "cm_rf_dbscan_html = cm_to_html_table(cm_rf_dbscan, ['High', 'Low'])\n",
        "cm_et_dbscan_html = cm_to_html_table(cm_et_dbscan, ['High', 'Low'])\n",
        "\n",
        "# Figure 3: Feature Importance\n",
        "top_features = feature_importance.nlargest(12, 'RF_Importance')\n",
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Bar(\n",
        "    y=top_features['Feature'],\n",
        "    x=top_features['RF_Importance']*100,\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color=top_features['RF_Importance']*100,\n",
        "        colorscale='Blues',\n",
        "        showscale=False\n",
        "    ),\n",
        "    text=[f'{v:.1f}%' for v in top_features['RF_Importance']*100],\n",
        "    textposition='outside'\n",
        "))\n",
        "fig3.update_layout(\n",
        "    title='Feature Importance (Random Forest with DBSCAN)',\n",
        "    xaxis_title='Importance (%)',\n",
        "    yaxis_title='',\n",
        "    height=500,\n",
        "    yaxis=dict(autorange='reversed')\n",
        ")\n",
        "fig3_html = fig3.to_html(include_plotlyjs='cdn', div_id='fig3')\n",
        "\n",
        "# Figure 4: Ensemble Methods Comparison\n",
        "fig4 = go.Figure()\n",
        "for metric in ['Accuracy', 'F1_Score', 'ROC_AUC']:\n",
        "    fig4.add_trace(go.Bar(\n",
        "        name=metric,\n",
        "        x=ensemble_df['Method'],\n",
        "        y=ensemble_df[metric],\n",
        "        text=[f'{v:.3f}' for v in ensemble_df[metric]],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "fig4.update_layout(\n",
        "    title='Ensemble Methods Comparison',\n",
        "    xaxis_title='Method',\n",
        "    yaxis_title='Score',\n",
        "    barmode='group',\n",
        "    height=500\n",
        ")\n",
        "fig4_html = fig4.to_html(include_plotlyjs='cdn', div_id='fig4')\n",
        "\n",
        "# Figure 5: Gini Index Comparison (if available)\n",
        "if gini_comparison is not None:\n",
        "    fig5 = go.Figure()\n",
        "    fig5.add_trace(go.Bar(\n",
        "        x=gini_comparison['Classification'],\n",
        "        y=gini_comparison['Gini Index'],\n",
        "        text=[f'{v:.4f}' for v in gini_comparison['Gini Index']],\n",
        "        textposition='outside',\n",
        "        marker=dict(color=['#e74c3c', '#27ae60'])\n",
        "    ))\n",
        "    fig5.update_layout(\n",
        "        title='Class Purity: Gini Index Comparison',\n",
        "        yaxis_title='Gini Index (lower is better)',\n",
        "        height=400\n",
        "    )\n",
        "    fig5_html = fig5.to_html(include_plotlyjs='cdn', div_id='fig5')\n",
        "else:\n",
        "    fig5_html = '<p>Gini Index calculation not available</p>'\n",
        "\n",
        "print(\"  All visualizations created\")\n",
        "\n",
        "# ==================== GENERATE HTML DASHBOARD ====================\n",
        "print(\"\\n[5/10] Generating HTML dashboard...\")\n",
        "\n",
        "html_content = f'''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Health Risk Prediction Analysis - Complete Dashboard</title>\n",
        "    <style>\n",
        "        * {{\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            box-sizing: border-box;\n",
        "        }}\n",
        "\n",
        "        body {{\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            line-height: 1.6;\n",
        "            color: #333;\n",
        "            background: #f5f5f5;\n",
        "        }}\n",
        "\n",
        "        .container {{\n",
        "            max-width: 1400px;\n",
        "            margin: 0 auto;\n",
        "            padding: 20px;\n",
        "        }}\n",
        "\n",
        "        header {{\n",
        "            background: linear-gradient(135deg, #2E86AB 0%, #A23B72 100%);\n",
        "            color: white;\n",
        "            padding: 40px 20px;\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "\n",
        "        h1 {{\n",
        "            font-size: 2.5em;\n",
        "            margin-bottom: 10px;\n",
        "        }}\n",
        "\n",
        "        .subtitle {{\n",
        "            font-size: 1.2em;\n",
        "            opacity: 0.9;\n",
        "        }}\n",
        "\n",
        "        .section {{\n",
        "            background: white;\n",
        "            padding: 30px;\n",
        "            margin-bottom: 30px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "\n",
        "        h2 {{\n",
        "            color: #2E86AB;\n",
        "            margin-bottom: 20px;\n",
        "            padding-bottom: 10px;\n",
        "            border-bottom: 3px solid #2E86AB;\n",
        "        }}\n",
        "\n",
        "        h3 {{\n",
        "            color: #555;\n",
        "            margin: 20px 0 10px 0;\n",
        "        }}\n",
        "\n",
        "        .metrics-grid {{\n",
        "            display: grid;\n",
        "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
        "            gap: 20px;\n",
        "            margin: 20px 0;\n",
        "        }}\n",
        "\n",
        "        .metric-card {{\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 8px;\n",
        "            text-align: center;\n",
        "        }}\n",
        "\n",
        "        .metric-value {{\n",
        "            font-size: 2em;\n",
        "            font-weight: bold;\n",
        "            margin: 10px 0;\n",
        "        }}\n",
        "\n",
        "        .metric-label {{\n",
        "            font-size: 0.9em;\n",
        "            opacity: 0.9;\n",
        "        }}\n",
        "\n",
        "        .highlight {{\n",
        "            background: #fff3cd;\n",
        "            border-left: 4px solid #ffc107;\n",
        "            padding: 15px;\n",
        "            margin: 20px 0;\n",
        "            border-radius: 4px;\n",
        "        }}\n",
        "\n",
        "        .cm-table {{\n",
        "            width: 100%;\n",
        "            border-collapse: collapse;\n",
        "            margin: 20px 0;\n",
        "        }}\n",
        "\n",
        "        .cm-table th, .cm-table td {{\n",
        "            border: 1px solid #ddd;\n",
        "            padding: 12px;\n",
        "            text-align: center;\n",
        "        }}\n",
        "\n",
        "        .cm-table th {{\n",
        "            background: #2E86AB;\n",
        "            color: white;\n",
        "            font-weight: bold;\n",
        "        }}\n",
        "\n",
        "        .cm-table td {{\n",
        "            background: #f9f9f9;\n",
        "        }}\n",
        "\n",
        "        .comparison-table {{\n",
        "            width: 100%;\n",
        "            border-collapse: collapse;\n",
        "            margin: 20px 0;\n",
        "        }}\n",
        "\n",
        "        .comparison-table th {{\n",
        "            background: #2E86AB;\n",
        "            color: white;\n",
        "            padding: 12px;\n",
        "            text-align: left;\n",
        "        }}\n",
        "\n",
        "        .comparison-table td {{\n",
        "            padding: 10px;\n",
        "            border-bottom: 1px solid #ddd;\n",
        "        }}\n",
        "\n",
        "        .comparison-table tr:hover {{\n",
        "            background: #f5f5f5;\n",
        "        }}\n",
        "\n",
        "        .footer {{\n",
        "            text-align: center;\n",
        "            padding: 20px;\n",
        "            color: #666;\n",
        "            font-size: 0.9em;\n",
        "        }}\n",
        "\n",
        "        .plot-container {{\n",
        "            margin: 20px 0;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <header>\n",
        "            <h1>Health Risk Prediction Analysis</h1>\n",
        "            <p class=\"subtitle\">Complete Analysis Dashboard - Food Desert Impact on Metabolic Health</p>\n",
        "            <p style=\"font-size: 0.9em; margin-top: 10px;\">Generated on {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}</p>\n",
        "        </header>\n",
        "\n",
        "        <!-- OVERVIEW -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Executive Summary</h2>\n",
        "            <div class=\"metrics-grid\">\n",
        "                <div class=\"metric-card\">\n",
        "                    <div class=\"metric-label\">Best Model</div>\n",
        "                    <div class=\"metric-value\">{best_ensemble['Method']}</div>\n",
        "                </div>\n",
        "                <div class=\"metric-card\">\n",
        "                    <div class=\"metric-label\">Final Accuracy</div>\n",
        "                    <div class=\"metric-value\">{best_ensemble['Accuracy']:.1%}</div>\n",
        "                </div>\n",
        "                <div class=\"metric-card\">\n",
        "                    <div class=\"metric-label\">Total Improvement</div>\n",
        "                    <div class=\"metric-value\">+{(best_ensemble['Accuracy']-rf_three['Accuracy'])*100:.1f}%</div>\n",
        "                </div>\n",
        "                <div class=\"metric-card\">\n",
        "                    <div class=\"metric-label\">Food Desert Rank</div>\n",
        "                    <div class=\"metric-value\">#{food_rank}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Key Finding:</strong> Food_Access_Barrier_Index ranks #{food_rank} with {food_importance_rf*100:.2f}% importance,\n",
        "                demonstrating that food desert has a significant and independent impact on health risk, controlling for income,\n",
        "                poverty, education, healthcare, and urban-rural factors.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- STEP 1: THREE-CLASS BASELINE -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Step 1: Three-Class Classification (Baseline)</h2>\n",
        "\n",
        "            <h3>Approach</h3>\n",
        "            <p>Initial attempt to classify counties into three risk categories (High, Medium, Low) based on Health_Risk_Score.</p>\n",
        "\n",
        "            <p><strong>Health Risk Score Formula:</strong><br>\n",
        "            Health_Risk_Score = 0.6  (% Adults with Obesity / 100) + 0.4  (% Adults with Diabetes / 100)</p>\n",
        "\n",
        "            <h3>Results</h3>\n",
        "            <table class=\"comparison-table\">\n",
        "                <thead>\n",
        "                    <tr>\n",
        "                        <th>Model</th>\n",
        "                        <th>Accuracy</th>\n",
        "                        <th>F1-Score</th>\n",
        "                        <th>Cohen Kappa</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr>\n",
        "                        <td>Random Forest</td>\n",
        "                        <td>{rf_three['Accuracy']:.4f}</td>\n",
        "                        <td>{rf_three['F1_Weighted']:.4f}</td>\n",
        "                        <td>{rf_three['Cohens_Kappa']:.4f}</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>Extra Trees</td>\n",
        "                        <td>{et_three['Accuracy']:.4f}</td>\n",
        "                        <td>{et_three['F1_Weighted']:.4f}</td>\n",
        "                        <td>{et_three['Cohens_Kappa']:.4f}</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3>Confusion Matrices</h3>\n",
        "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
        "                <div>\n",
        "                    <h4>Random Forest</h4>\n",
        "                    {cm_rf_three_html}\n",
        "                </div>\n",
        "                <div>\n",
        "                    <h4>Extra Trees</h4>\n",
        "                    {cm_et_three_html}\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Problem Identified:</strong> Poor performance (57-59% accuracy) due to ambiguous \"Medium\" class boundaries.\n",
        "                The model struggled to distinguish between Medium and High/Low categories.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- GINI INDEX COMPARISON -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Class Purity Analysis: Gini Index</h2>\n",
        "            <p>To quantify why three-class classification failed, we calculated the Gini Index for class purity.</p>\n",
        "\n",
        "            <div class=\"plot-container\">\n",
        "                {fig5_html}\n",
        "            </div>\n",
        "\n",
        "            <p><strong>Interpretation:</strong></p>\n",
        "            <ul style=\"margin-left: 20px;\">\n",
        "                <li>Lower Gini Index = More pure/homogeneous classes = Easier to classify</li>\n",
        "                <li>Higher Gini Index = More mixed/heterogeneous classes = Harder to classify</li>\n",
        "            </ul>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Insight:</strong> Binary classification has significantly lower Gini Index, indicating cleaner class separation\n",
        "                and explaining why it outperforms three-class classification.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- STEP 2: BINARY CLASSIFICATION -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Step 2: Binary Classification (Improved)</h2>\n",
        "\n",
        "            <h3>Approach</h3>\n",
        "            <p>Simplified to binary classification (High vs Low risk) using median obesity rate as threshold.</p>\n",
        "\n",
        "            <h3>Results</h3>\n",
        "            <table class=\"comparison-table\">\n",
        "                <thead>\n",
        "                    <tr>\n",
        "                        <th>Model</th>\n",
        "                        <th>Accuracy</th>\n",
        "                        <th>F1-Score</th>\n",
        "                        <th>ROC-AUC</th>\n",
        "                        <th>Improvement</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr>\n",
        "                        <td>Random Forest</td>\n",
        "                        <td>{rf_binary['Accuracy']:.4f}</td>\n",
        "                        <td>{rf_binary['F1_Score']:.4f}</td>\n",
        "                        <td>{rf_binary['ROC_AUC']:.4f}</td>\n",
        "                        <td style=\"color: green;\">+{(rf_binary['Accuracy']-rf_three['Accuracy'])*100:.1f}%</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>Extra Trees</td>\n",
        "                        <td>{et_binary['Accuracy']:.4f}</td>\n",
        "                        <td>{et_binary['F1_Score']:.4f}</td>\n",
        "                        <td>{et_binary['ROC_AUC']:.4f}</td>\n",
        "                        <td style=\"color: green;\">+{(et_binary['Accuracy']-et_three['Accuracy'])*100:.1f}%</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3>Confusion Matrices</h3>\n",
        "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
        "                <div>\n",
        "                    <h4>Random Forest</h4>\n",
        "                    {cm_rf_binary_html}\n",
        "                </div>\n",
        "                <div>\n",
        "                    <h4>Extra Trees</h4>\n",
        "                    {cm_et_binary_html}\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Achievement:</strong> Significant improvement of ~12% accuracy by eliminating ambiguous \"Medium\" class.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- STEP 3: DBSCAN NOISE FILTERING -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Step 3: DBSCAN Noise Filtering</h2>\n",
        "\n",
        "            <h3>Approach</h3>\n",
        "            <p>Applied DBSCAN clustering to identify and remove noisy/outlier samples from training data.</p>\n",
        "\n",
        "            <h3>Results</h3>\n",
        "            <table class=\"comparison-table\">\n",
        "                <thead>\n",
        "                    <tr>\n",
        "                        <th>Model</th>\n",
        "                        <th>Accuracy</th>\n",
        "                        <th>F1-Score</th>\n",
        "                        <th>ROC-AUC</th>\n",
        "                        <th>Improvement</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr>\n",
        "                        <td>RF (Binary Baseline)</td>\n",
        "                        <td>{rf_binary['Accuracy']:.4f}</td>\n",
        "                        <td>{rf_binary['F1_Score']:.4f}</td>\n",
        "                        <td>{rf_binary['ROC_AUC']:.4f}</td>\n",
        "                        <td>-</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>RF (DBSCAN Cleaned)</td>\n",
        "                        <td>{rf_dbscan['Accuracy']:.4f}</td>\n",
        "                        <td>{rf_dbscan['F1_Score']:.4f}</td>\n",
        "                        <td>{rf_dbscan['ROC_AUC']:.4f}</td>\n",
        "                        <td style=\"color: green;\">+{(rf_dbscan['Accuracy']-rf_binary['Accuracy'])*100:.1f}%</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>ET (DBSCAN Cleaned)</td>\n",
        "                        <td>{et_dbscan['Accuracy']:.4f}</td>\n",
        "                        <td>{et_dbscan['F1_Score']:.4f}</td>\n",
        "                        <td>{et_dbscan['ROC_AUC']:.4f}</td>\n",
        "                        <td style=\"color: green;\">+{(et_dbscan['Accuracy']-et_binary['Accuracy'])*100:.1f}%</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3>Confusion Matrices</h3>\n",
        "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
        "                <div>\n",
        "                    <h4>Random Forest (DBSCAN)</h4>\n",
        "                    {cm_rf_dbscan_html}\n",
        "                </div>\n",
        "                <div>\n",
        "                    <h4>Extra Trees (DBSCAN)</h4>\n",
        "                    {cm_et_dbscan_html}\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Milestone:</strong> Random Forest achieved {rf_dbscan['Accuracy']:.1%} accuracy through noise removal.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- STEP 4: ENSEMBLE METHODS -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Step 4: Ensemble Methods Comparison</h2>\n",
        "\n",
        "            <h3>Approach</h3>\n",
        "            <p>Tested multiple ensemble techniques to determine if combining models could improve performance.</p>\n",
        "\n",
        "            <div class=\"plot-container\">\n",
        "                {fig5_html}\n",
        "            </div>\n",
        "\n",
        "            <table class=\"comparison-table\">\n",
        "                <thead>\n",
        "                    <tr>\n",
        "                        <th>Method</th>\n",
        "                        <th>Accuracy</th>\n",
        "                        <th>F1-Score</th>\n",
        "                        <th>ROC-AUC</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "'''\n",
        "\n",
        "for _, row in ensemble_df.iterrows():\n",
        "    html_content += f'''\n",
        "                    <tr>\n",
        "                        <td>{row['Method']}</td>\n",
        "                        <td>{row['Accuracy']:.4f}</td>\n",
        "                        <td>{row['F1_Score']:.4f}</td>\n",
        "                        <td>{row['ROC_AUC']:.4f}</td>\n",
        "                    </tr>\n",
        "'''\n",
        "\n",
        "html_content += f'''\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Best Method:</strong> {best_ensemble['Method']} achieved {best_ensemble['Accuracy']:.1%} accuracy.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- FEATURE IMPORTANCE -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Feature Importance Analysis</h2>\n",
        "\n",
        "            <h3>Top Features (Random Forest with DBSCAN)</h3>\n",
        "            <div class=\"plot-container\">\n",
        "                {fig3_html}\n",
        "            </div>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Food Desert Impact:</strong> Food_Access_Barrier_Index ranks #{food_rank} out of {len(feature_importance)} features\n",
        "                with {food_importance_rf*100:.2f}% importance, demonstrating significant independent contribution to health risk prediction\n",
        "                after controlling for socioeconomic factors.\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- MODEL EVOLUTION -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Overall Model Evolution</h2>\n",
        "            <div class=\"plot-container\">\n",
        "                {fig1_html}\n",
        "            </div>\n",
        "\n",
        "            <h3>Summary of Improvements</h3>\n",
        "            <table class=\"comparison-table\">\n",
        "                <thead>\n",
        "                    <tr>\n",
        "                        <th>Stage</th>\n",
        "                        <th>RF Accuracy</th>\n",
        "                        <th>ET Accuracy</th>\n",
        "                        <th>Key Action</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr>\n",
        "                        <td>Step 1: Three-Class</td>\n",
        "                        <td>{rf_three['Accuracy']:.1%}</td>\n",
        "                        <td>{et_three['Accuracy']:.1%}</td>\n",
        "                        <td>Baseline - Failed</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>Step 2: Binary</td>\n",
        "                        <td>{rf_binary['Accuracy']:.1%}</td>\n",
        "                        <td>{et_binary['Accuracy']:.1%}</td>\n",
        "                        <td>Simplified classification</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td>Step 3: DBSCAN</td>\n",
        "                        <td>{rf_dbscan['Accuracy']:.1%}</td>\n",
        "                        <td>{et_dbscan['Accuracy']:.1%}</td>\n",
        "                        <td>Noise removal</td>\n",
        "                    </tr>\n",
        "                    <tr style=\"font-weight: bold;\">\n",
        "                        <td>Step 4: Ensemble</td>\n",
        "                        <td colspan=\"2\">{best_ensemble['Accuracy']:.1%}</td>\n",
        "                        <td>Best final model</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <div class=\"highlight\">\n",
        "                <strong>Total Improvement:</strong> {(best_ensemble['Accuracy']-rf_three['Accuracy'])*100:.1f} percentage points\n",
        "                (from {rf_three['Accuracy']:.1%} to {best_ensemble['Accuracy']:.1%})\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- CONCLUSIONS -->\n",
        "        <div class=\"section\">\n",
        "            <h2>Conclusions</h2>\n",
        "\n",
        "            <h3>Key Findings</h3>\n",
        "            <ol style=\"margin-left: 20px; line-height: 2;\">\n",
        "                <li><strong>Classification Strategy:</strong> Binary classification significantly outperformed three-class\n",
        "                    classification due to clearer class boundaries (validated by Gini Index analysis)</li>\n",
        "\n",
        "                <li><strong>Data Quality:</strong> DBSCAN noise filtering provided significant improvement,\n",
        "                    demonstrating that data quality is crucial for model performance</li>\n",
        "\n",
        "                <li><strong>Food Desert Impact:</strong> Food_Access_Barrier_Index ranks #{food_rank} with {food_importance_rf*100:.2f}%\n",
        "                    importance, confirming independent contribution to health risk beyond socioeconomic factors</li>\n",
        "\n",
        "                <li><strong>Model Performance:</strong> Best result achieved {best_ensemble['Accuracy']:.1%} accuracy using {best_ensemble['Method']},\n",
        "                    representing a {(best_ensemble['Accuracy']-rf_three['Accuracy'])*100:.1f} percentage point improvement from baseline</li>\n",
        "\n",
        "                <li><strong>Optimization Insights:</strong> Ensemble methods and DBSCAN noise filtering were the most effective optimization strategies,\n",
        "                    with data quality being a crucial factor for model performance</li>\n",
        "            </ol>\n",
        "\n",
        "            <h3>Implications</h3>\n",
        "            <p>This analysis demonstrates that food desert characteristics have measurable impact on county-level\n",
        "            metabolic health outcomes, independent of traditional socioeconomic factors. The strong predictive\n",
        "            performance of Food_Access_Barrier_Index suggests that improving food access could be an effective\n",
        "            public health intervention strategy.</p>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"footer\">\n",
        "            <p>Health Risk Prediction Analysis Dashboard</p>\n",
        "            <p>Generated on {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}</p>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# ==================== SAVE HTML ====================\n",
        "print(\"\\n[6/10] Saving HTML dashboard...\")\n",
        "\n",
        "output_file = 'health_risk_analysis_dashboard.html'\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write(html_content)\n",
        "\n",
        "file_size = len(html_content) / 1024\n",
        "print(f\"  Dashboard saved: {output_file}\")\n",
        "print(f\"  File size: {file_size:.1f} KB\")\n",
        "\n",
        "# ==================== DOWNLOAD IN COLAB ====================\n",
        "print(\"\\n[7/10] Preparing download for Colab...\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(output_file)\n",
        "    print(\"  Dashboard downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"  Not in Colab environment - file saved locally\")\n",
        "\n",
        "# ==================== DISPLAY IN COLAB ====================\n",
        "print(\"\\n[8/10] Displaying dashboard in Colab...\")\n",
        "\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(HTML(f'<a href=\"{output_file}\" target=\"_blank\">Click here to open dashboard in new tab</a>'))\n",
        "    print(\"  Dashboard link displayed above\")\n",
        "except:\n",
        "    print(\"  Could not display link - open file manually\")\n",
        "\n",
        "# ==================== COMPLETION ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DASHBOARD GENERATION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDashboard file: {output_file}\")\n",
        "print(\"\\nDashboard includes:\")\n",
        "print(\"  - Executive summary with key metrics\")\n",
        "print(\"  - Step 1: Three-class classification baseline\")\n",
        "print(\"  - Gini Index class purity analysis\")\n",
        "print(\"  - Step 2: Binary classification improvement\")\n",
        "print(\"  - Step 3: DBSCAN noise filtering\")\n",
        "print(\"  - Step 4: Ensemble methods comparison\")\n",
        "print(\"  - Feature importance with food desert ranking\")\n",
        "print(\"  - Overall model evolution visualization\")\n",
        "print(\"  - Comprehensive conclusions\")\n",
        "print(\"\\nAll content based on your actual experimental results\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "-p9AhsSf5NW5",
        "outputId": "5d23b123-36af-4b64-ecaa-a6ddee3890a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "UNIFIED DASHBOARD GENERATOR (COLAB VERSION)\n",
            "======================================================================\n",
            "\n",
            "[1/10] Loading all result files...\n",
            "  All CSV files loaded successfully\n",
            "\n",
            "[2/10] Calculating Gini Index for class purity comparison...\n",
            "  Three-Class Gini: 0.6666\n",
            "  Binary Gini: 0.4999\n",
            "\n",
            "[3/10] Extracting key metrics...\n",
            "  Best accuracy: 0.6918\n",
            "  Food Desert rank: #3\n",
            "  Food Desert importance: 12.21%\n",
            "\n",
            "[4/10] Creating visualizations...\n",
            "  All visualizations created\n",
            "\n",
            "[5/10] Generating HTML dashboard...\n",
            "\n",
            "[6/10] Saving HTML dashboard...\n",
            "  Dashboard saved: health_risk_analysis_dashboard.html\n",
            "  File size: 52.8 KB\n",
            "\n",
            "[7/10] Preparing download for Colab...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f9fc207-d60d-48f7-97c2-b0a0431c39ef\", \"health_risk_analysis_dashboard.html\", 54086)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Dashboard downloaded successfully!\n",
            "\n",
            "[8/10] Displaying dashboard in Colab...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"health_risk_analysis_dashboard.html\" target=\"_blank\">Click here to open dashboard in new tab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Dashboard link displayed above\n",
            "\n",
            "======================================================================\n",
            "DASHBOARD GENERATION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "Dashboard file: health_risk_analysis_dashboard.html\n",
            "\n",
            "Dashboard includes:\n",
            "  - Executive summary with key metrics\n",
            "  - Step 1: Three-class classification baseline\n",
            "  - Gini Index class purity analysis\n",
            "  - Step 2: Binary classification improvement\n",
            "  - Step 3: DBSCAN noise filtering\n",
            "  - Step 4: Ensemble methods comparison\n",
            "  - Feature importance with food desert ranking\n",
            "  - Overall model evolution visualization\n",
            "  - Comprehensive conclusions\n",
            "\n",
            "All content based on your actual experimental results\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('step1_model_comparison_results.csv')\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlbkzbcI56Ut",
        "outputId": "cec7bae0-bd21-49d4-c9a5-be42341bd654"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Feature_Set', 'Model', 'Accuracy', 'F1_Weighted', 'F1_Macro', 'Cohens_Kappa', 'ROC_AUC']\n"
          ]
        }
      ]
    }
  ]
}