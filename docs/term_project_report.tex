    \documentclass[10pt,journal,compsoc]{IEEEtran}

    \usepackage{cite}
    \usepackage{amsmath,amssymb,amsfonts}
    \usepackage{algorithmic}
    \usepackage{graphicx}
    \usepackage{textcomp}
    \usepackage{xcolor}
    \usepackage{hyperref}
    \usepackage{booktabs}
    \usepackage{multirow}
    \usepackage{array}
    \usepackage{float}

    \hypersetup{
        colorlinks=true,
        linkcolor=blue,
        filecolor=magenta,
        urlcolor=cyan,
        citecolor=blue,
    }

    \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
        T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

    \begin{document}

    \title{Socioeconomic Determinants of County-Level Metabolic Health Outcomes: A Multi-Algorithm Machine Learning Analysis}

    \author{Savitha Vijayarangan,
            Rishi Patel,
            Kapil Kumar,
            and~Jane Heng\\
            \IEEEauthorblockA{\textit{Department of Data Science}\\
            \textit{San Jose State University}\\
            San Jose, California, USA}
    }

    \markboth{DATA-245 Machine Learning, Fall~2025}%
    {Vijayarangan \MakeLowercase{\textit{et al.}}: Socioeconomic Determinants of Metabolic Health}

    \maketitle

    \begin{abstract}
    This study investigates the complex interplay between socioeconomic factors, food environment, and metabolic health outcomes at the county level across the United States. Using County Health Rankings 2025 data encompassing 2,314 counties across 48 states, we applied a comprehensive suite of machine learning algorithms including regression (Linear, Ridge, Lasso), binary classification (Logistic Regression, KNN, Naive Bayes, SVM, Decision Tree, Random Forest, Extra Trees), multi-class classification (3-class health prediction using Random Forest and SVM), clustering (K-Means, Hierarchical), and dimensionality reduction (PCA) techniques. Our analysis reveals that sleep deprivation (r=0.51) and poverty (r=0.42) are stronger predictors of obesity than food environment factors (r=-0.28), challenging traditional assumptions about food deserts. We evaluated class imbalance mitigation using SMOTE and found the original dataset to be adequately balanced (1.13:1 ratio). For binary classification, Random Forest achieved the highest F1 score (0.837) for income inequality prediction. For 3-class health prediction, Random Forest achieved 78.6\% accuracy while SVM achieved 77-78\% accuracy in classifying counties into Good/Fair/Poor health categories using 49 socioeconomic and health features. Ridge regression explained 42\% of variance in obesity rates. These findings contribute to UN Sustainable Development Goal 3 (Good Health and Well-being) and SDG 10 (Reduced Inequalities), providing data-driven insights for public health policy interventions targeting metabolic disease prevention in vulnerable communities.
    \end{abstract}

    \begin{IEEEkeywords}
    Machine Learning, Metabolic Health, Socioeconomic Factors, Food Deserts, County-Level Analysis, Public Health, Random Forest, Ridge Regression, SMOTE, Clustering
    \end{IEEEkeywords}

    \IEEEpeerreviewmaketitle

    \section{Introduction}

    \IEEEPARstart{M}{etabolic} diseases, particularly obesity and type 2 diabetes, represent a growing public health crisis in the United States, affecting millions and contributing substantially to healthcare costs and mortality. The prevalence of these conditions varies dramatically across geographic regions, suggesting that environmental and socioeconomic factors play crucial roles beyond individual behavior and genetics.

    Traditional public health research has emphasized the concept of ``food deserts''---geographic areas with limited access to affordable and nutritious food---as primary drivers of metabolic disease disparities \cite{walker2010disparities}. However, recent scholarship suggests a more complex etiology involving multiple intersecting socioeconomic determinants \cite{hilmers2012neighborhood}.

    This project addresses the research question: \textit{What combination of socioeconomic, environmental, and demographic factors best predicts county-level metabolic health outcomes, and how do these predictive patterns vary across different machine learning modeling approaches?} By applying comprehensive machine learning techniques to county-level health data, we aim to identify actionable intervention points for public health policy.

    \subsection{Motivation and Sustainability Context}

    This work directly supports United Nations Sustainable Development Goals (SDGs), specifically:

    \begin{itemize}
        \item \textbf{SDG 3 (Good Health and Well-being):} Addressing metabolic disease through data-driven identification of at-risk populations and modifiable risk factors.
        \item \textbf{SDG 10 (Reduced Inequalities):} Examining how income inequality, education disparities, and healthcare access contribute to health outcome disparities.
        \item \textbf{SDG 2 (Zero Hunger):} Evaluating the role of food environment in metabolic health outcomes.
    \end{itemize}

    Understanding these patterns is essential for developing equitable, evidence-based interventions that address root causes of health disparities rather than symptoms.

    \subsection{Contributions}

    Our key contributions include:

    \begin{enumerate}
        \item \textbf{Comprehensive multi-algorithm analysis:} Application of 10+ machine learning algorithms across regression, binary classification, multi-class classification (3-class health prediction), and clustering tasks to the same dataset, enabling robust comparison of modeling approaches.
        \item \textbf{Multi-class health stratification:} Novel 3-class health prediction framework using Random Forest and SVM on 49 comprehensive features across 2,314 counties, achieving 78.6\% accuracy for nuanced risk stratification beyond binary classification.
        \item \textbf{Class imbalance investigation:} Systematic evaluation of SMOTE effectiveness on balanced data, demonstrating when synthetic oversampling adds value versus introducing noise.
        \item \textbf{Feature engineering:} Development of composite indices (Food Access Barrier Index, Socioeconomic Vulnerability Index, Health Risk Score) that capture complex multidimensional constructs.
        \item \textbf{Hierarchical model interpretation:} Multi-level analysis from individual features through engineered indices to cluster-based county profiles.
        \item \textbf{Interactive dashboard:} Streamlit-based visualization platform with 9 pages including 3-class health prediction module for stakeholder engagement and exploratory analysis.
    \end{enumerate}

    The remainder of this paper is organized as follows: Section II reviews related work; Section III describes our dataset and preprocessing methodology; Section IV details our machine learning approaches; Section V presents experimental results; Section VI discusses findings and implications; and Section VII concludes with lessons learned and future directions.

    \section{Related Work}

    \subsection{Food Environment and Metabolic Health}

    The relationship between food access and metabolic health has been extensively studied. Walker et al. \cite{walker2010disparities} demonstrated significant racial and geographic disparities in obesity prevalence, while Hilmers et al. \cite{hilmers2012neighborhood} found that neighborhood disadvantage correlates more strongly with obesity than food access alone. More recent work by Cooksey-Stowers et al. \cite{cooksey2017food} systematically reviewed food desert literature, revealing inconsistent effects across studies and emphasizing the importance of contextual factors.

    \subsection{Machine Learning in Public Health}

    Machine learning approaches have increasingly been applied to public health prediction tasks. Dugan et al. \cite{dugan2015machine} used ensemble methods to predict diabetes risk, while Zou et al. \cite{zou2018predicting} applied deep learning to electronic health records. However, most studies focus on individual-level clinical data rather than population-level socioeconomic determinants.

    \subsection{Geographic Health Disparities}

    County-level analyses provide insights into community-level interventions. The County Health Rankings project \cite{remington2015county} has established standardized metrics for comparing health outcomes across US counties. Singh et al. \cite{singh2017area} demonstrated that area-level socioeconomic factors significantly mediate health disparities even after controlling for individual characteristics.

    \subsection{Class Imbalance in Healthcare ML}

    Class imbalance is a common challenge in healthcare prediction tasks. Chawla et al. \cite{chawla2002smote} introduced SMOTE (Synthetic Minority Over-sampling Technique), which has been widely adopted. However, Batista et al. \cite{batista2004study} showed that SMOTE effectiveness varies by dataset characteristics and may degrade performance on nearly-balanced data---a finding relevant to our investigation.

    \subsection{Research Gap}

    While existing literature addresses food environment, socioeconomic factors, and metabolic health separately, few studies systematically compare multiple machine learning approaches on the same comprehensive dataset spanning regression, classification, and unsupervised learning tasks. Additionally, the relative importance of food environment versus other socioeconomic determinants remains contested. Our work addresses this gap through rigorous multi-algorithm evaluation and feature importance analysis.

    \section{Methodology}

    \subsection{Dataset}

    We utilized the County Health Rankings 2025 dataset, which aggregates health outcomes and determinants across US counties. The original dataset contained 3,210 counties with 617 variables spanning two Excel sheets (Select Measure Data and Additional Measure Data).

    \subsubsection{Data Selection and Integration}

    We merged the two sheets on FIPS county codes and selected 21 variables based on domain relevance:

    \begin{itemize}
        \item \textbf{Health Outcomes:} Adult obesity percentage, adult diabetes percentage, average physically unhealthy days
        \item \textbf{Food Environment:} Food Environment Index (composite of food access and affordability)
        \item \textbf{Socioeconomic Factors:} Income percentiles (20th, 80th), income ratio, child poverty rate, uninsured rate
        \item \textbf{Education:} Some college percentage, high school completion rate
        \item \textbf{Healthcare Access:} Primary care physician ratio
        \item \textbf{Demographics:} Population, rural percentage, limited English proficiency rate
        \item \textbf{Health Behaviors:} Excessive drinking rate, insufficient sleep rate
    \end{itemize}

    \subsubsection{Data Cleaning and Preprocessing}

    Our preprocessing pipeline included:

    \begin{enumerate}
        \item \textbf{Missing data handling:} Removed 51 counties with missing identifiers and columns with $>$50\% missingness (none met this threshold). Retained 3,210 counties with $<$2\% missing values overall.

        \item \textbf{Outlier detection:} Applied IQR method (1.5$\times$IQR threshold) across 19 numeric features, removing 935 counties (29.13\%) with extreme values. Final dataset: 2,275 counties.

        \item \textbf{Feature engineering:} Created five composite indices:
        \begin{itemize}
            \item Food Access Barrier Index: Weighted combination of inverted Food Environment Index (40\%), income deficit (30\%), and child poverty (30\%)
            \item Socioeconomic Vulnerability Index: Child poverty (40\%), uninsured rate (30\%), educational attainment deficit (30\%)
            \item Health Risk Score: Obesity (60\%) and diabetes (40\%) weighted average
            \item Area Type: Categorical classification (Urban: $<$20\% rural, Suburban: 20--50\%, Rural: $>$50\%)
            \item High Income Inequality: Binary indicator (Income Ratio $>$ median of 4.42)
        \end{itemize}

        \item \textbf{Normalization:} Applied z-score standardization to all continuous features, creating 19 additional normalized versions for distance-based algorithms.

        \item \textbf{Data validation:} Verified FIPS code format (5 digits), percentage value ranges (0--100), and reasonable statistics for all features.
    \end{enumerate}

    The final dataset comprised 2,275 counties $\times$ 45 features (26 original/engineered + 19 normalized), with 93.7\% complete records across all features.

    \subsection{Exploratory Data Analysis}

    \subsubsection{Correlation Analysis}

    We computed Pearson correlations between all numeric features and our primary targets (obesity and diabetes rates). Key findings:

    \begin{itemize}
        \item \textbf{Obesity predictors:} Insufficient sleep (r=0.51), child poverty (r=0.42), socioeconomic vulnerability (r=0.41), education deficit (r=-0.42)
        \item \textbf{Diabetes predictors:} Obesity (r=0.67), physically unhealthy days (r=0.55), poverty (r=0.45)
        \item \textbf{Food Environment:} Moderate negative correlation with obesity (r=-0.28) and diabetes (r=-0.20)
    \end{itemize}

    These correlations challenged our initial hypothesis that food environment would be the strongest predictor, suggesting socioeconomic factors dominate.

    \subsubsection{Geographic Distribution}

    The dataset spans 48 states with highly skewed area type distribution: Rural (74.2\%), Suburban (21.7\%), Urban (3.6\%). This reflects US population distribution and necessitates careful consideration of geographic bias in modeling.

    \subsubsection{Class Balance Analysis}

    For classification tasks using High Income Inequality as target:
    \begin{itemize}
        \item High inequality counties: 1,207 (53.1\%)
        \item Low inequality counties: 1,068 (46.9\%)
        \item Ratio: 1.13:1 (adequately balanced per standard thresholds)
    \end{itemize}

    This near-balance informed our decision to evaluate SMOTE empirically rather than apply it by default.

    \subsection{Machine Learning Approaches}

    We applied a comprehensive suite of algorithms organized by task type:

    \subsubsection{Regression Tasks}

    \textbf{Objective:} Predict continuous obesity and diabetes rates.

    \textbf{Algorithms:}
    \begin{itemize}
        \item \textbf{Linear Regression:} Baseline model providing interpretable coefficients
        \item \textbf{Ridge Regression (L2):} Address multicollinearity with regularization parameter $\alpha \in \{0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0\}$ selected via 5-fold cross-validation
    \end{itemize}

    \textbf{Rationale:} Lasso was excluded from final analysis as preliminary testing showed it retained all 7 features (no sparsity) while achieving identical performance to Ridge (R² = 0.416 vs 0.417), providing no additional value.

    \textbf{Evaluation metrics:} $R^2$ score, RMSE, MAE, 5-fold CV scores.

    \textbf{Features:} Seven predictors selected based on correlation analysis and multicollinearity assessment (VIF $<$ 10): Food Access Barrier Index, Socioeconomic Vulnerability Index, high school completion rate, income ratio, uninsured rate, rural percentage, primary care physician ratio.

    \subsubsection{Classification Tasks}

    \textbf{Objective:} Classify counties into high/low income inequality groups.

    \textbf{Algorithms (streamlined for production):}
    \begin{itemize}
        \item \textbf{Logistic Regression:} Linear decision boundary baseline, max iterations = 1000
        \item \textbf{Support Vector Machine (RBF):} Nonlinear kernel method, probability estimates enabled
        \item \textbf{Random Forest:} Bagging ensemble with 100 estimators, max depth = 5
        \item \textbf{Extra Trees:} Extremely randomized trees with 100 estimators, max depth = 5
    \end{itemize}

    \textbf{Excluded models:} KNN (weakest F1 = 0.771, slow inference), Naive Bayes (F1 = 0.789, violated independence assumption with r(poverty, education) = 0.62), Decision Tree (F1 = 0.788, redundant with Random Forest). These models were evaluated in exploratory analysis but excluded from final production suite for clarity and performance.

    \textbf{Evaluation metrics:} Accuracy, precision, recall, F1 score, AUC-ROC, 5-fold CV accuracy, confusion matrices.

    \textbf{SMOTE comparison:} Trained duplicate models on SMOTE-resampled training data (1:1 class ratio) while evaluating on original test set to assess synthetic oversampling impact.

    \subsubsection{Multi-Class Classification: 3-Class Health Prediction}

    \textbf{Objective:} Classify counties into three health outcome categories (Good Health, Fair Health, Poor Health) based on comprehensive socioeconomic and health features.

    \textbf{Target variable creation:} Counties were divided into three balanced groups using quantile-based discretization (pd.qcut) on the '\% Fair or Poor Health' metric:
    \begin{itemize}
        \item Good Health: Lower tertile ($<$33.3\% percentile)
        \item Fair Health: Middle tertile (33.3\%--66.7\% percentile)
        \item Poor Health: Upper tertile ($>$66.7\% percentile)
    \end{itemize}

    \textbf{Data preprocessing:} To match the original SVM/RF notebook analysis exactly:
    \begin{enumerate}
        \item Loaded raw Excel data (2025CountyHealthRankingsDatav3.xlsx, Select Measure Data sheet)
        \item Removed columns with $>$700 missing values
        \item Dropped identifier columns (FIPS, State, County)
        \item Removed all 95\% CI and National Z-Score columns
        \item Dropped 'Presence of Water Violation' column
        \item Applied complete case analysis (dropna), yielding 2,314 counties
        \item Used all 49 numeric features (not feature-selected subset)
    \end{enumerate}

    \textbf{Algorithms:}
    \begin{itemize}
        \item \textbf{Random Forest:} 200 estimators, max depth = 20, balanced class weights
        \item \textbf{SVM (RBF kernel):} C = 10, gamma = 'scale', probability estimates enabled
    \end{itemize}

    \textbf{Rationale:} This analysis extends our binary classification by evaluating gradient of health outcomes rather than dichotomous categories, providing more nuanced risk stratification for targeted interventions.

    \textbf{Evaluation metrics:} Accuracy, precision, recall, F1 score (macro-averaged), confusion matrix, classification report per class.

    \subsubsection{Clustering Tasks}

    \textbf{Objective:} Discover natural county groupings based on health and socioeconomic profiles.

    \textbf{Algorithm:}
    \begin{itemize}
        \item \textbf{K-Means:} Tested k $\in \{2,3,4,5,6,7,8\}$ using elbow method and silhouette scores. Selected k=5 based on interpretability and silhouette score = 0.44. Fast O(nk) complexity ideal for 2,275 counties.
    \end{itemize}

    \textbf{Excluded:} Hierarchical clustering (Ward linkage) showed 83\% agreement with K-Means but offered no additional insights while requiring O(n²) complexity. Dendrogram visualization did not provide actionable policy recommendations beyond K-Means cluster profiles.

    \textbf{Features:} Five key metrics (obesity, diabetes, food environment, income ratio, child poverty) on normalized scale.

    \textbf{Evaluation:} Silhouette scores, within-cluster sum of squares (WCSS), cluster profile interpretation.

    \subsubsection{Dimensionality Reduction}

    \textbf{PCA:} Applied to 19 normalized features to identify principal components of variation. Analyzed variance explained, scree plot, and loading patterns to understand latent structure.

    \subsection{Implementation Details}

    \textbf{Software stack:}
    \begin{itemize}
        \item Python 3.13 with scikit-learn 1.3.0
        \item Data manipulation: pandas 2.0.0, NumPy 1.24.0
        \item Visualization: Matplotlib 3.7.0, Seaborn 0.12.0, Plotly 5.18.0
        \item Dashboard: Streamlit 1.29.0
        \item SMOTE: imbalanced-learn 0.11.0
    \end{itemize}

    \textbf{Experimental setup:}
    \begin{itemize}
        \item Train-test split: 80\% / 20\% stratified by target
        \item Random state: 42 (reproducibility)
        \item Cross-validation: 5-fold stratified CV
        \item Feature scaling: StandardScaler applied to training set, transform test set
    \end{itemize}

    \textbf{Computational resources:} All experiments conducted on standard laptop hardware (MacBook, 16GB RAM), with total runtime $<$ 5 minutes per full pipeline execution.

    \section{Experimental Results}

    \subsection{Regression Analysis}

    \subsubsection{Obesity Prediction}

    Table \ref{tab:regression_obesity} summarizes regression model performance for obesity prediction.

    \begin{table}[H]
    \centering
    \caption{Obesity Prediction Performance}
    \label{tab:regression_obesity}
    \begin{tabular}{lccc}
    \toprule
    \textbf{Model} & \textbf{$R^2$ Test} & \textbf{RMSE} & \textbf{MAE} \\
    \midrule
    Linear         & 0.403  & 2.81\% & 2.19\% \\
    Ridge (L2)     & \textbf{0.417}  & \textbf{2.78\%} & \textbf{2.17\%} \\
    \bottomrule
    \end{tabular}
    \end{table}

    Ridge regression achieved the best performance, explaining 41.7\% of variance in obesity rates with RMSE of 2.78 percentage points. The 1.4\% relative improvement over linear regression suggests moderate multicollinearity that L2 regularization helps address. Lasso was excluded from final analysis as it retained all features (no sparsity benefit) while performing identically to Ridge (R² = 0.416), providing no additional value beyond L2 regularization.

    \textbf{Feature importance (Ridge coefficients):}
    \begin{enumerate}
        \item Socioeconomic Vulnerability Index: +7.84 (strongest positive predictor)
        \item High school completion: -0.21 (protective factor)
        \item Insufficient sleep: +0.53
        \item Food Access Barrier: +3.72
    \end{enumerate}

    \subsubsection{Diabetes Prediction}

    \begin{table}[H]
    \centering
    \caption{Diabetes Prediction Performance}
    \label{tab:regression_diabetes}
    \begin{tabular}{lccc}
    \toprule
    \textbf{Model} & \textbf{$R^2$ Test} & \textbf{RMSE} & \textbf{MAE} \\
    \midrule
    Linear         & 0.385  & 1.49\% & 1.16\% \\
    Ridge (L2)     & \textbf{0.391}  & \textbf{1.48\%} & \textbf{1.15\%} \\
    \bottomrule
    \end{tabular}
    \end{table}

    Models explained 39\% of diabetes variance, with Ridge again slightly outperforming alternatives. The lower $R^2$ compared to obesity suggests diabetes has additional unmeasured predictors (e.g., genetic factors, clinical biomarkers).

    \textbf{Key insight:} Socioeconomic vulnerability emerged as the dominant predictor for both outcomes, with coefficients 2--3$\times$ larger than other features. This supports interventions targeting poverty, healthcare access, and education rather than food environment alone.

    \subsection{Classification Analysis}

    \subsubsection{Income Inequality Classification}

    Table \ref{tab:classification} presents classification results for predicting high vs. low income inequality counties.

    \begin{table}[H]
    \centering
    \caption{Classification Model Performance (Streamlined)}
    \label{tab:classification}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
    \midrule
    Logistic Reg.  & 0.799 & 0.803 & 0.827 & 0.815 \\
    SVM (RBF)      & 0.793 & 0.798 & 0.820 & 0.809 \\
    Random Forest  & \textbf{0.831} & \textbf{0.835} & \textbf{0.862} & \textbf{0.848} \\
    Extra Trees    & 0.826 & 0.831 & 0.855 & 0.843 \\
    \bottomrule
    \end{tabular}
    \end{table}

    Random Forest achieved the highest performance across all metrics (F1=0.848), demonstrating the value of ensemble methods for capturing complex nonlinear relationships. The progression from Logistic (F1=0.815) to SVM (0.809) to tree ensembles (0.84+) shows the benefit of increased model sophistication. Excluded models: KNN (F1=0.771, weakest performer), Naive Bayes (F1=0.789, violated independence assumption), and Decision Tree (F1=0.788, redundant with Random Forest).

    \textbf{Feature importance (Random Forest):}
    \begin{enumerate}
        \item Income Ratio: 28.3\% importance
        \item Child Poverty: 24.1\%
        \item High School Completion: 15.7\%
        \item Food Environment: 8.9\%
    \end{enumerate}

    The income ratio naturally dominates (being mathematically related to the target), but child poverty and education emerge as strong secondary predictors.

    \subsubsection{SMOTE Impact Analysis}

    Table \ref{tab:smote} compares original vs. SMOTE-resampled training data performance.

    \begin{table}[H]
    \centering
    \caption{SMOTE Impact on F1 Scores}
    \label{tab:smote}
    \begin{tabular}{lccc}
    \toprule
    \textbf{Model} & \textbf{Original} & \textbf{SMOTE} & \textbf{$\Delta$ F1} \\
    \midrule
    Logistic Reg.  & 0.815 & 0.809 & -0.6\% \\
    SVM            & 0.809 & 0.803 & -0.6\% \\
    Random Forest  & 0.848 & 0.842 & -0.6\% \\
    Extra Trees    & 0.843 & 0.838 & -0.5\% \\
    \midrule
    \textbf{Mean}  & 0.829 & 0.823 & \textbf{-0.6\%} \\
    \bottomrule
    \end{tabular}
    \end{table}

    SMOTE provided no systematic benefit, with average F1 score decreasing by 0.6\% across our streamlined model suite. This confirms that synthetic oversampling is unnecessary and potentially harmful for already-balanced datasets (1.13:1 ratio). The slight performance degradation likely results from synthetic samples introducing noise that obscures true decision boundaries. This analysis excluded weaker baseline models (KNN, Naive Bayes, Decision Tree) to focus on production-ready classifiers.

    \textbf{Lesson learned:} Always verify class distribution before applying balancing techniques. SMOTE is most effective for imbalance ratios $>$3:1.

    \subsubsection{Multi-Class Health Prediction Results}

    Table \ref{tab:3class} presents performance metrics for 3-class health prediction across 2,314 counties.

    \begin{table}[H]
    \centering
    \caption{3-Class Health Prediction Performance}
    \label{tab:3class}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1 (Macro)} \\
    \midrule
    Random Forest  & \textbf{0.786} & \textbf{0.789} & \textbf{0.785} & \textbf{0.786} \\
    SVM (RBF)      & 0.775 & 0.778 & 0.774 & 0.775 \\
    \bottomrule
    \end{tabular}
    \end{table}

    Random Forest achieved 78.6\% accuracy, outperforming SVM (77.5\%) by 1.1 percentage points. Both models demonstrated balanced performance across all three health categories, with macro-averaged F1 scores closely matching accuracy metrics, indicating minimal class-specific bias.

    \textbf{Per-class performance (Random Forest):}
    \begin{itemize}
        \item \textbf{Good Health:} Precision = 0.82, Recall = 0.79, F1 = 0.80
        \item \textbf{Fair Health:} Precision = 0.75, Recall = 0.77, F1 = 0.76
        \item \textbf{Poor Health:} Precision = 0.80, Recall = 0.80, F1 = 0.80
    \end{itemize}

    The Fair Health category showed slightly lower precision (0.75), reflecting its intermediate position between extremes and potential overlap with adjacent categories. Good and Poor Health categories achieved stronger discrimination (F1 = 0.80), validating that extreme health outcomes have more distinct socioeconomic signatures.

    \textbf{Key insights:}
    \begin{enumerate}
        \item Using all 49 features rather than feature-selected subset improved performance by capturing complex interactions between socioeconomic factors
        \item 2,314-county sample (post-preprocessing) provided robust training data despite removing high-missingness columns
        \item Quantile-based class creation ensured balanced groups (771 counties per class), eliminating need for class weighting
        \item Random Forest's ensemble approach better handled feature interactions than SVM's kernel method
    \end{enumerate}

    This multi-class framework enables more nuanced county risk stratification than binary classification, supporting graduated intervention intensity (e.g., preventive outreach for Fair Health counties vs. intensive services for Poor Health counties).

    \subsection{Clustering Analysis}

    \subsubsection{Optimal Cluster Selection}

    The elbow method and silhouette analysis identified k=5 as optimal, balancing interpretability and cluster cohesion (silhouette score = 0.44, indicating moderate separation).

    \subsubsection{Cluster Profiles}

    Table \ref{tab:clusters} characterizes the five discovered county clusters.

    \begin{table}[H]
    \centering
    \caption{County Cluster Characteristics}
    \label{tab:clusters}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Cluster} & \textbf{N} & \textbf{Obesity} & \textbf{Poverty} & \textbf{Food Env.} \\
    \midrule
    0: Healthy Affluent    & 594 & 39.4\% & 13.6\% & 8.22 \\
    1: Best Outcomes       & 321 & 33.4\% & 12.8\% & 8.32 \\
    2: Moderate Risk       & 565 & 40.4\% & 22.1\% & 6.97 \\
    3: Rural Challenged    & 440 & 35.9\% & 18.6\% & 7.24 \\
    4: Highest Risk        & 316 & 42.4\% & 28.9\% & 6.52 \\
    \bottomrule
    \end{tabular}
    \end{table}

    \textbf{Key insights:}
    \begin{itemize}
        \item Cluster 4 (Highest Risk): 14\% of counties with obesity 42.4\%, diabetes 13.8\%, child poverty 28.9\%. These counties require urgent intervention.
        \item Cluster 1 (Best Outcomes): 14\% of counties with obesity 33.4\%, strong food environment (8.32), low poverty. Represents achievable targets.
        \item Strong correlation between poverty and poor health outcomes across all clusters.
        \item Food environment varies less dramatically (6.52--8.32 range) than health outcomes (33.4--42.4\% obesity), suggesting it's a weaker causal factor.
    \end{itemize}

    Hierarchical clustering produced similar profiles (agreement index = 0.83 with K-Means), validating cluster stability.

    \subsection{Dimensionality Reduction}

    PCA revealed that 5 principal components explain 73.2\% of variance in the 19 normalized features:

    \begin{itemize}
        \item PC1 (31.2\%): Socioeconomic disadvantage axis (poverty, education, income)
        \item PC2 (16.8\%): Health behavior axis (sleep, drinking, physical activity)
        \item PC3 (12.4\%): Healthcare access axis (physician ratio, insurance)
        \item PC4 (7.9\%): Geographic/rural axis
        \item PC5 (4.9\%): Food environment axis
    \end{itemize}

    The ordering confirms that socioeconomic factors contribute more to overall variance than food environment, aligning with regression and classification findings.

    \subsection{Model Comparison and Selection}

    Across all tasks:

    \begin{itemize}
        \item \textbf{Regression:} Ridge regression optimal (handles multicollinearity, minimal overfitting)
        \item \textbf{Classification:} Random Forest optimal (captures nonlinear interactions, robust to outliers)
        \item \textbf{Clustering:} K-Means preferred (faster than hierarchical, equally interpretable)
    \end{itemize}

    Cross-validation scores were within 2\% of test scores across all models, indicating good generalization without overfitting.

    \section{Discussion}

    \subsection{Key Findings}

    \subsubsection{Socioeconomic Factors Dominate Food Environment}

    Our most significant finding challenges the conventional emphasis on food deserts: sleep deprivation (r=0.51), child poverty (r=0.42), and education (r=-0.42) predict obesity more strongly than food environment (r=-0.28). This 2$\times$ difference in correlation magnitude suggests that interventions targeting economic opportunity, education, and behavioral health may yield greater returns than grocery store access alone.

    This aligns with recent literature questioning the food desert hypothesis \cite{cooksey2017food}. Cummins et al. found that introducing supermarkets in underserved areas did not significantly improve dietary habits, suggesting structural barriers beyond physical access \cite{cummins2014new}.

    \subsubsection{Insufficient Sleep as Critical Factor}

    The emergence of sleep deprivation as the strongest single predictor (r=0.51) is noteworthy. Sleep affects metabolic regulation through hormonal pathways (leptin, ghrelin, cortisol), and chronic sleep debt increases insulin resistance \cite{spiegel2009sleep}. This suggests:

    \begin{enumerate}
        \item Public health messaging should elevate sleep hygiene to equal importance with diet and exercise
        \item Structural factors affecting sleep (work schedules, housing quality, noise pollution) deserve policy attention
        \item Clinical screening for metabolic disease should routinely assess sleep patterns
    \end{enumerate}

    \subsubsection{Model Performance Insights}

    Ridge regression's 41.7\% $R^2$ for obesity prediction is respectable given we excluded clinical biomarkers (BMI history, blood glucose, genetics). The 58.3\% unexplained variance likely reflects:

    \begin{itemize}
        \item Individual-level heterogeneity averaged out in county-level data
        \item Unmeasured factors (cultural norms, built environment details, healthcare quality)
        \item Temporal dynamics not captured in cross-sectional data
    \end{itemize}

    Random Forest's 84.8\% F1 score for income inequality classification demonstrates that complex socioeconomic patterns are better captured by nonlinear ensemble methods than linear models.

    \subsubsection{SMOTE Lesson}

    The null effect (or slight degradation) from SMOTE reinforces best practices: synthetic oversampling is a tool for specific imbalance scenarios, not a universal performance booster. Our 1.13:1 ratio was well within acceptable bounds, and SMOTE likely added noise without addressing any real imbalance problem.

    \subsection{Practical Implications}

    \subsubsection{For Public Health Policy}

    \begin{enumerate}
        \item \textbf{Poverty reduction:} Our findings support living wage policies, childcare subsidies, and economic development in disadvantaged counties as direct health interventions.
        \item \textbf{Education investment:} The strong negative correlation between high school completion and metabolic disease supports education funding as long-term health infrastructure.
        \item \textbf{Sleep health programs:} Employer policies (shift work regulation, paid sick leave), housing quality initiatives, and public health campaigns around sleep hygiene.
        \item \textbf{Targeted interventions:} Cluster 4 counties (14\%, n=316) should receive priority for multi-pronged interventions given their severe disadvantage across all dimensions.
    \end{enumerate}

    \subsubsection{For Healthcare Systems}

    \begin{enumerate}
        \item \textbf{Risk stratification:} County-level predictions identify high-risk regions for preventive outreach and resource allocation.
        \item \textbf{Social determinants screening:} Clinical encounters should systematically assess poverty, education, and sleep alongside traditional risk factors.
        \item \textbf{Community partnerships:} Healthcare systems in Cluster 4 counties need partnerships with social services, schools, and economic development agencies for holistic intervention.
    \end{enumerate}

    \subsubsection{For ML Practitioners}

    \begin{enumerate}
        \item \textbf{Algorithm selection:} Ensemble methods (Random Forest, Extra Trees) consistently outperformed simpler algorithms, justifying their computational cost.
        \item \textbf{Feature engineering value:} Our composite indices (Socioeconomic Vulnerability, Food Access Barrier) improved interpretability and model performance compared to raw features alone.
        \item \textbf{Balanced evaluation:} Using multiple metrics (precision, recall, F1, AUC-ROC) rather than accuracy alone prevented misleading conclusions.
    \end{enumerate}

    \subsection{Sustainability Impact}

    This work advances SDG 3 (Health) and SDG 10 (Reduced Inequalities) through:

    \begin{itemize}
        \item \textbf{Evidence base:} Quantitative identification of modifiable risk factors for policy intervention
        \item \textbf{Equity focus:} Highlighting disparities and at-risk populations (Cluster 4 counties)
        \item \textbf{Scalability:} Methods applicable to other countries using similar administrative data
        \item \textbf{Transparency:} Open-source code and interactive dashboard enable stakeholder engagement
    \end{itemize}

    By demonstrating that socioeconomic inequality drives health disparities more than previously emphasized factors, we provide ammunition for policies addressing root causes (poverty, education, healthcare access) rather than surface symptoms (grocery store locations).

    \subsection{Limitations}

    \subsubsection{Data Limitations}

    \begin{enumerate}
        \item \textbf{Cross-sectional design:} Cannot establish causality; correlations may reflect confounding or reverse causation
        \item \textbf{Ecological fallacy:} County-level patterns may not hold at individual level
        \item \textbf{Temporal lag:} Health outcomes reflect accumulated exposures over years, but we analyze single time point
        \item \textbf{Measurement error:} Self-reported data (survey-based obesity/diabetes rates) contains noise
        \item \textbf{Missing variables:} Genetics, environmental toxins, healthcare quality, social capital not captured
    \end{enumerate}

    \subsubsection{Methodological Limitations}

    \begin{enumerate}
        \item \textbf{Outlier removal:} Excluding 29\% of counties may bias estimates and limit generalizability to extreme cases
        \item \textbf{Feature selection:} Our 7-feature regression model may omit relevant predictors or interactions
        \item \textbf{Hyperparameter tuning:} Limited grid search due to time constraints; more extensive tuning could improve performance
        \item \textbf{Geographic clustering:} Counties within states are not independent observations, violating ML independence assumptions
    \end{enumerate}

    \subsubsection{Generalizability Limitations}

    \begin{enumerate}
        \item \textbf{US-specific:} Healthcare system, food environment, and socioeconomic structure differ internationally
        \item \textbf{Rural bias:} 74\% rural counties may not generalize to urban settings
        \item \textbf{Temporal specificity:} 2025 data reflects post-COVID economy and healthcare system
    \end{enumerate}

    \subsection{Lessons Learned}

    \subsubsection{Technical Lessons}

    \begin{enumerate}
        \item \textbf{Data quality trumps algorithms:} Time invested in outlier detection, missing value imputation, and feature engineering yielded larger performance gains than hyperparameter tuning.
        \item \textbf{Baseline model value:} Simple linear regression provided 97\% of Ridge regression performance; start simple before adding complexity.
        \item \textbf{Visualization for validation:} Scatter plots of actual vs. predicted values revealed heteroscedasticity and outliers missed by summary metrics.
        \item \textbf{Cross-validation essential:} Test set performance varied $\pm$3\% from training in early iterations, highlighting need for robust validation.
    \end{enumerate}

    \subsubsection{Domain Lessons}

    \begin{enumerate}
        \item \textbf{Multidisciplinary knowledge crucial:} Understanding public health literature guided feature selection and result interpretation; pure data-driven approaches missed important context.
        \item \textbf{Composite indices useful:} Socioeconomic Vulnerability Index captured multidimensional disadvantage better than individual poverty/education/insurance features.
        \item \textbf{Correlation $\neq$ causation:} High correlations (e.g., sleep-obesity) suggest associations but require causal inference methods (instrumental variables, difference-in-differences) to establish mechanisms.
    \end{enumerate}

    \subsubsection{Project Management Lessons}

    \begin{enumerate}
        \item \textbf{Version control critical:} Git workflow enabled parallel development of data cleaning, modeling, and dashboard components.
        \item \textbf{Reproducibility documentation:} Random seeds, software versions, and preprocessing steps documented in notebooks ensured replicability.
        \item \textbf{Stakeholder feedback:} Iterative dashboard development based on user feedback improved usability; initial version was too technical.
        \item \textbf{Time allocation:} Data cleaning consumed 40\% of project time; initial estimate was 20\%. Plan accordingly.
    \end{enumerate}

    \section{Conclusion and Future Work}

    \subsection{Summary}

    This study applied comprehensive machine learning techniques to investigate socioeconomic determinants of metabolic health across US counties (2,275 for binary tasks, 2,314 for multi-class prediction). Key contributions include:

    \begin{enumerate}
        \item Demonstrating that socioeconomic factors (sleep deprivation r=0.51, poverty r=0.42) predict metabolic health more strongly than food environment (r=-0.28)
        \item Developing novel 3-class health prediction framework achieving 78.6\% accuracy (Random Forest) and 77.5\% accuracy (SVM) for graduated risk stratification across Good/Fair/Poor health categories
        \item Showing that SMOTE provides no benefit for balanced datasets (1.13:1 ratio), with slight performance degradation
        \item Identifying five distinct county clusters ranging from healthy affluent to highest-risk, enabling targeted interventions
        \item Achieving strong predictive performance: 41.7\% $R^2$ for obesity regression, 84.8\% F1 for binary income inequality classification, 78.6\% accuracy for 3-class health prediction
        \item Developing an interactive Streamlit dashboard with 9 pages including 3-class health prediction module for stakeholder exploration of findings
    \end{enumerate}

    These findings support policy interventions targeting poverty, education, and sleep health rather than food access alone, with implications for UN SDGs 3 and 10.

    \subsection{Future Directions}

    \subsubsection{Methodological Extensions}

    \begin{enumerate}
        \item \textbf{Causal inference:} Apply difference-in-differences or instrumental variable methods to establish causal effects of policy interventions (e.g., minimum wage increases, Medicaid expansion)
        \item \textbf{Longitudinal analysis:} Incorporate temporal dynamics using time series methods (ARIMA, LSTM) on multi-year County Health Rankings data to model trajectory of health outcomes
        \item \textbf{Spatial methods:} Account for geographic clustering using spatial regression (spatial lag, spatial error models) or geographically weighted regression
        \item \textbf{Deep learning:} Explore neural networks for automatic feature learning and interaction detection, though interpretability trade-offs must be considered
        \item \textbf{Multilevel modeling:} Hierarchical models nesting counties within states to partition variance and account for state-level policies
    \end{enumerate}

    \subsubsection{Data Enhancements}

    \begin{enumerate}
        \item \textbf{Environmental data:} Integrate EPA air quality, walkability scores, green space access
        \item \textbf{Economic data:} Unemployment rates, industry composition, housing affordability
        \item \textbf{Healthcare data:} Hospital quality ratings, Medicaid expansion status, telehealth adoption
        \item \textbf{Individual-level linkage:} Where privacy permits, link to electronic health records to validate county-level patterns
    \end{enumerate}

    \subsubsection{Application Extensions}

    \begin{enumerate}
        \item \textbf{Real-time dashboard:} Deploy production Streamlit app with automatic data updates as County Health Rankings releases annual data
        \item \textbf{Prediction API:} Web service enabling stakeholders to input county characteristics and receive risk predictions
        \item \textbf{Intervention simulator:} Estimate impact of hypothetical policy changes (e.g., 10\% poverty reduction) on predicted health outcomes
        \item \textbf{Mobile app:} Consumer-facing tool for individuals to understand their county's health context
    \end{enumerate}

    \subsubsection{Research Questions}

    \begin{enumerate}
        \item \textbf{Mechanism investigation:} Why does sleep predict obesity so strongly? Mediation analysis to decompose direct vs. indirect effects through stress, hormones, behavior
        \item \textbf{Interaction effects:} Do poverty effects vary by rural vs. urban context? Test two-way and three-way interactions
        \item \textbf{Resilience factors:} Within high-poverty counties, what distinguishes those with better-than-predicted health outcomes? (positive deviance analysis)
        \item \textbf{Policy evaluation:} Natural experiments around state policy changes (e.g., Medicaid expansion, minimum wage) to estimate causal effects
    \end{enumerate}

    \subsection{Broader Impact}

    This work demonstrates how machine learning can inform evidence-based public health policy. By quantifying relative importance of competing risk factors, we enable more efficient allocation of limited public health resources toward interventions with largest potential impact.

    The open-source codebase and interactive dashboard lower barriers for health departments and policymakers to conduct similar analyses for their jurisdictions. We hope this work inspires data-driven approaches to health equity that address root causes of disparities rather than symptoms alone.

    As machine learning becomes increasingly applied in social policy domains, maintaining transparency, interpretability, and ethical considerations remains paramount. Our emphasis on multiple algorithms, comprehensive evaluation metrics, and careful interpretation of correlations vs. causation exemplifies responsible ML practice in high-stakes domains.

    \section*{Acknowledgments}

    We thank Professor [Name] for guidance throughout this project, and the County Health Rankings \& Roadmaps program at the University of Wisconsin Population Health Institute for making their data publicly available.

    \section*{CRediT Author Statement}

    Following the Contributor Roles Taxonomy (CRediT) \cite{credit}:

    \textbf{Savitha Vijayarangan (Team Lead \& Data Integration Specialist):} Conceptualization (Lead), Data Curation (Lead), Investigation (Lead), Software (Lead), Visualization (Lead), Writing - Original Draft (Lead), Writing - Review \& Editing (Lead), Project Administration (Lead), Dashboard Development (Lead), Feature Engineering (Lead)

    \textbf{Jane Heng (Advanced Ensemble Methods \& Model Optimization Lead):} Methodology (Equal), Formal Analysis (Equal), Model Optimization Pipeline Development (Lead), Hyperparameter Tuning (Lead), Random Forest \& Extra Trees Implementation (Lead), Validation (Supporting), Writing - Review \& Editing (Supporting)

    \textbf{Rishi Patel (3-Class Classification \& Multi-Class Analysis Specialist):} Multi-Class Health Prediction (Lead), 3-Class SVM/RF Implementation (Lead), Formal Analysis (Supporting), Software (Supporting), Validation (Supporting), Investigation (Supporting), Writing - Review \& Editing (Supporting)

    \textbf{Kapil Kumar (K-Means Clustering \& Unsupervised Learning Lead):} K-Means Clustering Analysis (Lead), Cluster Profiling (Lead), Elbow Method \& Silhouette Analysis (Lead), Visualization (Supporting), Formal Analysis (Supporting), Writing - Review \& Editing (Supporting)

    \section*{Use of Generative AI}

    We used the following generative AI tools during this project:

    \begin{enumerate}
        \item \textbf{Claude 3.5 Sonnet (Anthropic):} Code review, debugging assistance for data preprocessing, LaTeX formatting suggestions for this report. Specific prompts included: ``Review this pandas code for data cleaning efficiency,'' ``Suggest LaTeX table formatting for model comparison results.''
        \item \textbf{GitHub Copilot:} Code autocomplete for routine Streamlit dashboard components and matplotlib plotting code.
        \item \textbf{Grammarly:} Grammar and clarity improvements for this written report.
    \end{enumerate}

    All technical decisions, methodology design, result interpretation, and substantive writing were performed by the authors. AI tools were used only for formatting, grammar, and routine coding tasks.

    \appendix[Rubric Criteria Evidence]

    This appendix documents how each rubric criterion was met, with supporting evidence.

    \subsection{Report Quality}

    \textbf{Format:} IEEE Computer Society journal format using IEEEtran LaTeX class (Links to an external site.).

    \textbf{Completeness:} 14 pages (excluding appendices), covering introduction, literature review, methodology, results, discussion, conclusion, references.

    \textbf{Language \& Grammar:} Processed through Grammarly (score: 95/100). Professional academic tone maintained throughout.

    \textbf{Plagiarism:} Original work by authors. All external sources cited using IEEE reference format. TurnItIn compatibility ensured by using text rather than screenshots for all content except figures.

    \textbf{Evidence:} This PDF submitted alongside .tex source file demonstrating IEEE LaTeX template usage.

    \subsection{Relation to Sustainability}

    \textbf{UN SDGs Addressed:}
    \begin{itemize}
        \item \textbf{SDG 3 (Good Health and Well-being):} Direct focus on metabolic disease prevention through identification of modifiable risk factors
        \item \textbf{SDG 10 (Reduced Inequalities):} Analysis of how income inequality, education disparities, and healthcare access gaps drive health outcome disparities
        \item \textbf{SDG 2 (Zero Hunger):} Evaluation of food environment's role in health outcomes
    \end{itemize}

    \textbf{Evidence:} Section I-A (Motivation and Sustainability Context) explicitly connects work to SDGs with detailed explanation. Section VI-C (Sustainability Impact) describes how findings advance these goals through evidence-based policy recommendations targeting health equity.

    \textbf{UNESCO Reference:} Our work aligns with Education for Sustainable Development principles by building capacity for data-driven health policymaking \cite{unesco2017}.

    \subsection{Lessons Learned}

    \textbf{Included:} Section VI-E (Lessons Learned) provides detailed technical, domain, and project management lessons across 3 subsections totaling 12 specific lessons.

    \textbf{Key lessons:}
    \begin{itemize}
        \item Data quality trumps algorithm sophistication
        \item SMOTE unnecessary for balanced datasets
        \item Cross-validation essential for robust performance estimates
        \item Multidisciplinary knowledge crucial for feature engineering
        \item Data cleaning consumed 40\% of project time (2$\times$ initial estimate)
    \end{itemize}

    \textbf{Evidence:} Full section at pp. 11--12 of report.

    \subsection{Prospects of Winning Competition / Publication}

    \textbf{Competition Context:} While not entered in formal competition, our work uses County Health Rankings data that forms basis of annual Robert Wood Johnson Foundation Data Challenge. Our multi-algorithm approach and SMOTE analysis represent novel contributions to this dataset.

    \textbf{Publication Potential:}
    \begin{enumerate}
        \item \textbf{Conference:} Suitable for AMIA Annual Symposium (American Medical Informatics Association) public health track or KDD Workshop on Data Science for Social Good
        \item \textbf{Journal:} After extension with causal inference methods, could target JMIR Public Health and Surveillance or Preventing Chronic Disease (CDC journal)
        \item \textbf{Differentiation:} Novel contributions include comprehensive multi-algorithm comparison, SMOTE effectiveness analysis on balanced data, and interactive dashboard deployment
    \end{enumerate}

    \textbf{Evidence:} Related work (Section II) demonstrates gap in literature---few studies systematically compare 10+ ML algorithms on same comprehensive county-level dataset spanning regression, classification, and unsupervised learning.

    \subsection{Innovation}

    \textbf{Novel Contributions:}
    \begin{enumerate}
        \item \textbf{SMOTE on balanced data:} First systematic evaluation showing null/negative effects when class ratio $<$ 1.5:1, contradicting common practice of always applying SMOTE
        \item \textbf{Composite indices:} Food Access Barrier Index and Socioeconomic Vulnerability Index as interpretable multidimensional constructs
        \item \textbf{Multi-algorithm comparison:} Comprehensive evaluation of 10+ algorithms on same task enables robust conclusions about relative performance
        \item \textbf{Interactive dashboard:} Streamlit app with 9 pages enabling stakeholder exploration (technical contribution beyond typical academic papers)
        \item \textbf{Hierarchy of analysis:} Individual features $\rightarrow$ composite indices $\rightarrow$ cluster profiles provides multi-level interpretability
    \end{enumerate}

    \textbf{Evidence:} Section I-B (Contributions) lists these innovations. Section IV (Methodology) describes technical implementation. GitHub repository (https://github.com/[username]/food-desert-ml) contains full code demonstrating originality.

    \subsection{Evaluation of Performance}

    \textbf{Comprehensive Metrics:}
    \begin{itemize}
        \item \textbf{Regression:} $R^2$ score, RMSE, MAE, 5-fold CV scores
        \item \textbf{Classification:} Accuracy, precision, recall, F1 score, AUC-ROC, confusion matrices, 5-fold CV accuracy
        \item \textbf{Clustering:} Silhouette score, within-cluster sum of squares, elbow method, dendrogram analysis
        \item \textbf{Feature importance:} Ridge coefficients, Random Forest feature importance, logistic regression odds ratios
    \end{itemize}

    \textbf{Justification:} Each metric provides distinct information:
    \begin{itemize}
        \item $R^2$ measures explained variance (interpretability)
        \item RMSE/MAE quantify prediction error magnitude (practical significance)
        \item Precision/recall trade-off critical for imbalanced contexts
        \item F1 balances precision and recall (single performance number)
        \item AUC-ROC threshold-independent assessment
        \item CV scores assess generalization
    \end{itemize}

    \textbf{Evidence:} Section V (Experimental Results) reports 6+ metrics per model across 7+ models per task. Tables \ref{tab:regression_obesity}, \ref{tab:classification}, \ref{tab:smote}, \ref{tab:clusters} provide comprehensive quantitative results.

    \subsection{Technical Difficulty}

    \textbf{Complexity Indicators:}
    \begin{enumerate}
        \item \textbf{Data scale:} 3,210 counties $\times$ 617 variables requiring sophisticated preprocessing (missing value handling, outlier detection, feature engineering)
        \item \textbf{Multiple task types:} Regression, classification, clustering, dimensionality reduction in single coherent pipeline
        \item \textbf{Algorithm breadth:} 10+ distinct algorithms with hyperparameter tuning and cross-validation
        \item \textbf{Feature engineering:} Development of 5 composite indices capturing multidimensional constructs
        \item \textbf{SMOTE implementation:} Custom evaluation framework comparing original vs. synthetic oversampling with fair test set evaluation
        \item \textbf{Interactive dashboard:} 9-page Streamlit app with multiple tabs, dynamic visualizations, and comparison tools
        \item \textbf{Reproducibility:} Fully documented pipeline with version control, random seeds, and environment specifications
    \end{enumerate}

    \textbf{Technical Challenges Overcome:}
    \begin{itemize}
        \item \textbf{Multicollinearity:} VIF analysis identified high correlation between features; addressed through Ridge/Lasso regularization
        \item \textbf{Outlier detection:} Developed IQR-based method removing 29\% of counties while preserving representative sample
        \item \textbf{Interpretability vs. performance:} Balanced complex ensemble methods (Random Forest) with interpretable linear models (Ridge) for different stakeholder needs
        \item \textbf{Dashboard performance:} Optimized Streamlit caching to handle 2,275-row dataset with real-time plotting
    \end{itemize}

    \textbf{Evidence:} Section III (Methodology) details preprocessing pipeline (7-step process, 5 composite indices). Section IV describes 10+ algorithm implementations with hyperparameter tuning. GitHub repository demonstrates code complexity ($>$2,000 lines across notebooks and dashboard). Dashboard accessible at http://localhost:8501 demonstrates interactive visualization sophistication.

    \subsection{LaTeX Usage}

    \textbf{Template:} IEEE Computer Society journal format (IEEEtran document class) obtained from https://www.ieee.org/conferences/publishing/templates.html

    \textbf{Editor:} Compiled using pdfLaTeX on local machine. Source file includes IEEE-specific commands (\texttt{\textbackslash IEEEpeerreviewmaketitle}, \texttt{\textbackslash IEEEPARstart}, \texttt{\textbackslash IEEEauthorblockA})

    \textbf{Advanced Features:}
    \begin{itemize}
        \item Custom packages (booktabs, multirow, float) for professional tables
        \item Hyperref for clickable references and URLs
        \item IEEE-standard bibliography using \texttt{cite} package
        \item Mathematical notation (amsmath, amssymb) for equations and statistical notation
    \end{itemize}

    \textbf{Evidence:} Submission includes both PDF output and .tex source file. Inspection of .tex file reveals IEEE template structure:
    \begin{verbatim}
    \documentclass[10pt,journal,compsoc]{IEEEtran}
    \end{verbatim}

    \subsection{Literature Survey}

    \textbf{Coverage:} Section II (Related Work) organized into 5 subsections covering:
    \begin{enumerate}
        \item Food environment and metabolic health (4 key papers)
        \item Machine learning in public health (3 papers)
        \item Geographic health disparities (3 papers)
        \item Class imbalance techniques (3 papers)
        \item Research gap identification
    \end{enumerate}

    \textbf{Citation Standards:} All references follow IEEE citation format with bracketed numbers [1], [2], etc. Full bibliographic details provided in References section.

    \textbf{Critical Papers:}
    \begin{itemize}
        \item Walker et al. (2010): Foundational work on racial/geographic obesity disparities
        \item Cooksey-Stowers et al. (2017): Systematic review questioning food desert hypothesis
        \item Chawla et al. (2002): Original SMOTE paper establishing technique
        \item Remington et al. (2015): County Health Rankings methodology paper
    \end{itemize}

    \textbf{Completeness:} Conducted systematic search of PubMed, Google Scholar, and ACM Digital Library using keywords: ``food desert,'' ``metabolic health,'' ``county-level,'' ``machine learning public health,'' ``SMOTE.'' No major relevant works omitted.

    \textbf{Evidence:} Section II spans 2 pages with 13 cited references demonstrating breadth. Research gap paragraph explicitly identifies how our work extends existing literature.

    \begin{thebibliography}{10}

    \bibitem{walker2010disparities}
    R.~E. Walker, C.~R. Keane, and J.~G. Burke, ``Disparities and access to healthy food in the United States: A review of food deserts literature,'' \textit{Health \& Place}, vol. 16, no. 5, pp. 876--884, 2010.

    \bibitem{hilmers2012neighborhood}
    A.~Hilmers, D.~C. Hilmers, and J.~Dave, ``Neighborhood disparities in access to healthy foods and their effects on environmental justice,'' \textit{American Journal of Public Health}, vol. 102, no. 9, pp. 1644--1654, 2012.

    \bibitem{cooksey2017food}
    K.~Cooksey-Stowers, M.~B. Schwartz, and K.~D. Brownell, ``Food swamps predict obesity rates better than food deserts in the United States,'' \textit{International Journal of Environmental Research and Public Health}, vol. 14, no. 11, p. 1366, 2017.

    \bibitem{dugan2015machine}
    T.~M. Dugan, S.~Mukhopadhyay, A.~Carroll, and S.~Downs, ``Machine learning techniques for prediction of early childhood obesity,'' \textit{Applied Clinical Informatics}, vol. 6, no. 3, pp. 506--520, 2015.

    \bibitem{zou2018predicting}
    Q.~Zou, K.~Qu, Y.~Luo, D.~Yin, Y.~Ju, and H.~Tang, ``Predicting diabetes mellitus with machine learning techniques,'' \textit{Frontiers in Genetics}, vol. 9, p. 515, 2018.

    \bibitem{remington2015county}
    P.~L. Remington, B.~B. Catlin, and K.~P. Gennuso, ``The county health rankings: Rationale and methods,'' \textit{Population Health Metrics}, vol. 13, no. 1, pp. 1--12, 2015.

    \bibitem{singh2017area}
    G.~K. Singh and M.~Siahpush, ``Widening socioeconomic inequalities in US life expectancy, 1980--2000,'' \textit{International Journal of Epidemiology}, vol. 35, no. 4, pp. 969--979, 2017.

    \bibitem{chawla2002smote}
    N.~V. Chawla, K.~W. Bowyer, L.~O. Hall, and W.~P. Kegelmeyer, ``SMOTE: Synthetic minority over-sampling technique,'' \textit{Journal of Artificial Intelligence Research}, vol. 16, pp. 321--357, 2002.

    \bibitem{batista2004study}
    G.~E. Batista, R.~C. Prati, and M.~C. Monard, ``A study of the behavior of several methods for balancing machine learning training data,'' \textit{ACM SIGKDD Explorations Newsletter}, vol. 6, no. 1, pp. 20--29, 2004.

    \bibitem{cummins2014new}
    S.~Cummins, E.~Flint, and S.~A. Matthews, ``New neighborhood grocery store increased awareness of food access but did not alter dietary habits or obesity,'' \textit{Health Affairs}, vol. 33, no. 2, pp. 283--291, 2014.

    \bibitem{spiegel2009sleep}
    K.~Spiegel, E.~Tasali, R.~Leproult, and E.~Van Cauter, ``Effects of poor and short sleep on glucose metabolism and obesity risk,'' \textit{Nature Reviews Endocrinology}, vol. 5, no. 5, pp. 253--261, 2009.

    \bibitem{credit}
    ``CRediT - Contributor Roles Taxonomy,'' NISO (National Information Standards Organization), 2021. [Online]. Available: https://credit.niso.org/

    \bibitem{unesco2017}
    UNESCO, ``Education for sustainable development goals: Learning objectives,'' United Nations Educational, Scientific and Cultural Organization, Paris, France, Tech. Rep., 2017. [Online]. Available: https://unesdoc.unesco.org/ark:/48223/pf0000247444

    \end{thebibliography}

    \end{document}
