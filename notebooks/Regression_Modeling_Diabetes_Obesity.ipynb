{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Modeling: Predicting Diabetes & Obesity Rates\n",
    "\n",
    "**Course:** DATA-245 Machine Learning  \n",
    "**Analyst:** Jane Heng (Regression Lead)  \n",
    "**Group 3:** Savitha, Rishi, Kapil, Jane  \n",
    "**Date:** November 12, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Build predictive models to estimate county-level diabetes and obesity rates using:\n",
    "- Food access indicators (Food_Access_Barrier_Index)\n",
    "- Socioeconomic factors (poverty, income, education)\n",
    "- Demographic variables\n",
    "\n",
    "**Models:** OLS Regression, Ridge Regression, Lasso Regression\n",
    "\n",
    "**Goal:** Identify which features contribute most to metabolic health outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load cleaned dataset\ndf = pd.read_csv('../data/output/cleaned_health_data.csv')\n\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Counties: {len(df):,}\")\nprint(f\"\\nTarget variables:\")\nprint(f\"  • % Adults with Obesity: {df['% Adults with Obesity'].mean():.2f}% (avg)\")\nprint(f\"  • % Adults with Diabetes: {df['% Adults with Diabetes'].mean():.2f}% (avg)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection\n",
    "\n",
    "Select features based on:\n",
    "1. Domain knowledge (food access, socioeconomic factors)\n",
    "2. Correlation analysis\n",
    "3. Avoiding multicollinearity (VIF < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available features: 7/7\n",
      "\n",
      "Selected features:\n",
      "  1. Food_Access_Barrier_Index\n",
      "  2. Socioeconomic_Vulnerability_Index\n",
      "  3. % Completed High School\n",
      "  4. Income Ratio\n",
      "  5. % Uninsured\n",
      "  6. % Rural\n",
      "  7. Primary Care Physicians Ratio\n"
     ]
    }
   ],
   "source": [
    "# Define predictor features\n",
    "feature_list = [\n",
    "    'Food_Access_Barrier_Index',          # PRIMARY: Food desert indicator\n",
    "    'Socioeconomic_Vulnerability_Index',  # Composite socioeconomic measure\n",
    "    '% Completed High School',            # Education\n",
    "    'Income Ratio',                       # Income inequality\n",
    "    '% Uninsured',                        # Healthcare access\n",
    "    '% Rural',                            # Geographic context\n",
    "    'Primary Care Physicians Ratio'       # Healthcare infrastructure\n",
    "]\n",
    "\n",
    "# Check availability\n",
    "available_features = [f for f in feature_list if f in df.columns]\n",
    "print(f\"Available features: {len(available_features)}/{len(feature_list)}\")\n",
    "print(\"\\nSelected features:\")\n",
    "for i, feat in enumerate(available_features, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Adults with Obesity_normalized                          1.0000\n",
      "Health_Risk_Score_normalized                              0.9785\n",
      "Health_Risk_Score                                         0.9785\n",
      "% Adults with Diabetes_normalized                         0.6660\n",
      "% Adults with Diabetes                                    0.6660\n",
      "% Insufficient Sleep_normalized                           0.5146\n",
      "% Insufficient Sleep                                      0.5146\n",
      "% Children in Poverty_normalized                          0.4203\n",
      "% Children in Poverty                                     0.4203\n",
      "% Completed High School_normalized                       -0.4197\n",
      "% Completed High School                                  -0.4197\n",
      "80th Percentile Income_normalized                        -0.4180\n",
      "80th Percentile Income                                   -0.4180\n",
      "Socioeconomic_Vulnerability_Index                         0.4135\n",
      "Socioeconomic_Vulnerability_Index_normalized              0.4135\n",
      "% Excessive Drinking_normalized                          -0.4089\n",
      "% Excessive Drinking                                     -0.4089\n",
      "Food_Access_Barrier_Index_normalized                      0.4037\n",
      "Food_Access_Barrier_Index                                 0.4037\n",
      "Average Number of Physically Unhealthy Days_normalized    0.4024\n",
      "Average Number of Physically Unhealthy Days               0.4024\n",
      "20th Percentile Income_normalized                        -0.3951\n",
      "20th Percentile Income                                   -0.3951\n",
      "% Some College                                           -0.3612\n",
      "% Some College_normalized                                -0.3612\n",
      "Name: % Adults with Obesity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "ID_TOKENS = (\"fips\", \"geoid\", \"tract\", \"id\", \"code\")\n",
    "\n",
    "def _is_id_col(name: str) -> bool:\n",
    "    n = name.lower()\n",
    "    return any(tok in n for tok in ID_TOKENS)\n",
    "\n",
    "def _parse_ratio(s: str):\n",
    "    # \"a:b\" -> a / b   (returns np.nan if malformed or b == 0)\n",
    "    try:\n",
    "        a, b = s.split(\":\")\n",
    "        a = float(a.strip().replace(\",\", \"\"))\n",
    "        b = float(b.strip().replace(\",\", \"\"))\n",
    "        return np.nan if b == 0 else a / b\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def coerce_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if _is_id_col(c):\n",
    "            continue  # don't touch FIPS/IDs\n",
    "        if pd.api.types.is_numeric_dtype(out[c]):\n",
    "            continue\n",
    "\n",
    "        s = out[c].astype(str)\n",
    "\n",
    "        # Normalize whitespace\n",
    "        s = s.str.strip()\n",
    "\n",
    "        # Percent like \"12.3%\" -> 0.123\n",
    "        mask_pct = s.str.match(r\"^-?\\d+(\\.\\d+)?\\s*%$\")\n",
    "        out.loc[mask_pct, c] = (\n",
    "            s[mask_pct].str.replace(\"%\", \"\", regex=False).str.replace(\",\", \"\", regex=False).astype(float) / 100.0\n",
    "        )\n",
    "\n",
    "        # Ratio like \"2273:1\" or \"3:4\"\n",
    "        mask_ratio = s.str.match(r\"^-?\\d+(\\.\\d+)?\\s*:\\s*-?\\d+(\\.\\d+)?$\")\n",
    "        out.loc[mask_ratio, c] = s[mask_ratio].apply(_parse_ratio)\n",
    "\n",
    "        # Remove thousands separators (e.g., \"1,234.5\")\n",
    "        s2 = out[c].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "\n",
    "        # Yes/No / True/False\n",
    "        s2 = s2.str.replace(r\"^\\s*(yes|true)\\s*$\", \"1\", case=False, regex=True)\n",
    "        s2 = s2.str.replace(r\"^\\s*(no|false)\\s*$\", \"0\", case=False, regex=True)\n",
    "\n",
    "        # Final coercion\n",
    "        out[c] = pd.to_numeric(s2, errors=\"coerce\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- Usage ---\n",
    "# Ensure your target is correct\n",
    "target = \"% Adults with Obesity\"  # e.g., \"Diabetes_Rate\" or \"Obesity_Rate\"\n",
    "\n",
    "df_num = coerce_numeric(df)\n",
    "\n",
    "if target not in df_num.columns:\n",
    "    raise KeyError(f\"Target '{target}' not found in columns.\")\n",
    "\n",
    "# Keep only numeric predictors and drop rows with missing target\n",
    "numeric_cols = df_num.select_dtypes(include=np.number).columns.tolist()\n",
    "if target not in numeric_cols:\n",
    "    # try to coerce target specifically, then recheck\n",
    "    df_num[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "    numeric_cols = df_num.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Optional: exclude IDs that slipped through as numbers (rare but safe)\n",
    "numeric_cols = [c for c in numeric_cols if not _is_id_col(c)]\n",
    "\n",
    "df_corr = df_num.dropna(subset=[target])\n",
    "\n",
    "# Fast way: one shot correlation matrix for numeric columns only\n",
    "corr_to_target = (\n",
    "    df_corr[numeric_cols].corr(numeric_only=True)[target]\n",
    "    .dropna()\n",
    "    .sort_values(key=lambda s: s.abs(), ascending=False)\n",
    ")\n",
    "\n",
    "# Top K correlated features (excluding the target itself)\n",
    "top = corr_to_target.drop(index=target, errors=\"ignore\").head(25)\n",
    "print(top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check Correlations with Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlations with Target Variables:\n",
      "================================================================================\n",
      "\n",
      "% Adults with Obesity:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2273:1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m corrs = []\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m available_features:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     corr = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     corrs.append((feat, corr))\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Sort by absolute correlation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/core/series.py:2974\u001b[39m, in \u001b[36mSeries.corr\u001b[39m\u001b[34m(self, other, method, min_periods)\u001b[39m\n\u001b[32m   2971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m   2973\u001b[39m this_values = this.to_numpy(dtype=\u001b[38;5;28mfloat\u001b[39m, na_value=np.nan, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2974\u001b[39m other_values = \u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mspearman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkendall\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(method):\n\u001b[32m   2977\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m nanops.nancorr(\n\u001b[32m   2978\u001b[39m         this_values, other_values, method=method, min_periods=min_periods\n\u001b[32m   2979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/core/base.py:662\u001b[39m, in \u001b[36mIndexOpsMixin.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value, **kwargs)\u001b[39m\n\u001b[32m    658\u001b[39m         values = values.copy()\n\u001b[32m    660\u001b[39m     values[np.asanyarray(isna(\u001b[38;5;28mself\u001b[39m))] = na_value\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fillna) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()):\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.shares_memory(\u001b[38;5;28mself\u001b[39m._values[:\u001b[32m2\u001b[39m], result[:\u001b[32m2\u001b[39m]):\n\u001b[32m    666\u001b[39m         \u001b[38;5;66;03m# Take slices to improve performance of check\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '2273:1'"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "targets = ['% Adults with Obesity', '% Adults with Diabetes']\n",
    "\n",
    "print(\"Feature Correlations with Target Variables:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlation_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    corrs = []\n",
    "    for feat in available_features:\n",
    "        corr = df[target].corr(df[feat])\n",
    "        corrs.append((feat, corr))\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    corrs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    correlation_results[target] = corrs\n",
    "    \n",
    "    for feat, corr in corrs:\n",
    "        strength = \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "        print(f\"  {feat:45s}: {corr:7.4f}  [{strength}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Check for Multicollinearity (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m vif_data = pd.DataFrame()\n\u001b[32m      5\u001b[39m vif_data[\u001b[33m\"\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m\"\u001b[39m] = X_temp.columns\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m vif_data[\u001b[33m\"\u001b[39m\u001b[33mVIF\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_temp.columns))]\n\u001b[32m      7\u001b[39m vif_data = vif_data.sort_values(\u001b[33m'\u001b[39m\u001b[33mVIF\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mVariance Inflation Factor (VIF) Analysis:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/stats/outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m.fit().rsquared\n\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:921\u001b[39m, in \u001b[36mOLS.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mAn exception will be raised in the next version.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     warnings.warn(msg, ValueWarning)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_keys:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_keys.remove(\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:746\u001b[39m, in \u001b[36mWLS.__init__\u001b[39m\u001b[34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     weights = weights.squeeze()\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m nobs = \u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    749\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:200\u001b[39m, in \u001b[36mRegressionModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.pinv_wexog: Float64Array | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_attr.extend([\u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwendog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/model.py:270\u001b[39m, in \u001b[36mLikelihoodModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/model.py:95\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m missing = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m hasconst = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mhasconst\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mself\u001b[39m.data.k_constant\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28mself\u001b[39m.data.exog\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/model.py:135\u001b[39m, in \u001b[36mModel._handle_data\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     data = \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/data.py:675\u001b[39m, in \u001b[36mhandle_data\u001b[39m\u001b[34m(endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m     exog = np.asarray(exog)\n\u001b[32m    674\u001b[39m klass = handle_data_class_factory(endog, exog)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m             \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/data.py:88\u001b[39m, in \u001b[36mModelData.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._check_integrity()\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m._cache = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/statsmodels/base/data.py:133\u001b[39m, in \u001b[36mModelData._handle_constant\u001b[39m\u001b[34m(self, hasconst)\u001b[39m\n\u001b[32m    131\u001b[39m check_implicit = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    132\u001b[39m exog_max = np.max(\u001b[38;5;28mself\u001b[39m.exog, axis=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog_max\u001b[49m\u001b[43m)\u001b[49m.all():\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[33m'\u001b[39m\u001b[33mexog contains inf or nans\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    135\u001b[39m exog_min = np.min(\u001b[38;5;28mself\u001b[39m.exog, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# Calculate VIF for multicollinearity check\n",
    "X_temp = df[available_features].dropna()\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_temp.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_temp.values, i) for i in range(len(X_temp.columns))]\n",
    "vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF) Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(\"VIF < 5: Low multicollinearity\")\n",
    "print(\"VIF 5-10: Moderate multicollinearity\")\n",
    "print(\"VIF > 10: High multicollinearity (consider removing)\\n\")\n",
    "print(vif_data)\n",
    "\n",
    "high_vif = vif_data[vif_data['VIF'] > 10]['Feature'].tolist()\n",
    "if high_vif:\n",
    "    print(f\"\\n⚠️ Warning: High VIF detected for {len(high_vif)} features\")\n",
    "    print(\"   Ridge regression recommended to handle multicollinearity\")\n",
    "else:\n",
    "    print(\"\\n✓ No severe multicollinearity detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 2,132 counties\n",
      "Features: 7\n",
      "\n",
      "Feature statistics:\n",
      "       Food_Access_Barrier_Index  Socioeconomic_Vulnerability_Index  \\\n",
      "count                  2132.0000                          2132.0000   \n",
      "mean                      0.3127                             0.1374   \n",
      "std                       0.0694                             0.0429   \n",
      "min                       0.1290                             0.0422   \n",
      "25%                       0.2604                             0.1044   \n",
      "50%                       0.3112                             0.1310   \n",
      "75%                       0.3639                             0.1678   \n",
      "max                       0.5091                             0.2704   \n",
      "\n",
      "       % Completed High School  Income Ratio  % Uninsured   % Rural  \n",
      "count                2132.0000     2132.0000    2132.0000 2132.0000  \n",
      "mean                   89.3531        4.4631      10.1593   70.7201  \n",
      "std                     4.2655        0.6338       3.9559   27.8515  \n",
      "min                    75.3477        2.7572       3.3816    0.0000  \n",
      "25%                    86.3960        4.0096       7.0088   47.9528  \n",
      "50%                    90.0097        4.3763       9.2467   71.7036  \n",
      "75%                    92.6175        4.8317      12.7384  100.0000  \n",
      "max                   100.0000        6.3038      22.4344  100.0000  \n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrix and target variables\n",
    "X = df[available_features].copy()\n",
    "y_obesity = df['% Adults with Obesity'].copy()\n",
    "y_diabetes = df['% Adults with Diabetes'].copy()\n",
    "\n",
    "# Remove rows with missing values\n",
    "mask = X.notna().all(axis=1) & y_obesity.notna() & y_diabetes.notna()\n",
    "X = X[mask]\n",
    "y_obesity = y_obesity[mask]\n",
    "y_diabetes = y_diabetes[mask]\n",
    "\n",
    "print(f\"Final dataset size: {len(X):,} counties\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1,705 counties (80%)\n",
      "Test set: 427 counties (20%)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_obesity_train, y_obesity_test = train_test_split(\n",
    "    X, y_obesity, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "_, _, y_diabetes_train, y_diabetes_test = train_test_split(\n",
    "    X, y_diabetes, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} counties ({(1-test_size)*100:.0f}%)\")\n",
    "print(f\"Test set: {len(X_test):,} counties ({test_size*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 1: Ordinary Least Squares (OLS) Regression\n",
    "\n",
    "**Purpose:** Baseline interpretable model  \n",
    "**Pros:** Easy interpretation, statistical significance testing  \n",
    "**Cons:** Sensitive to multicollinearity, no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL 1: OLS REGRESSION\n",
      "================================================================================\n",
      "\n",
      "1. PREDICTING OBESITY RATES\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     12\u001b[39m model_ols_obesity = LinearRegression()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model_ols_obesity.fit(\u001b[43mX_train\u001b[49m, y_obesity_train)\n\u001b[32m     15\u001b[39m y_pred_train = model_ols_obesity.predict(X_train)\n\u001b[32m     16\u001b[39m y_pred_test = model_ols_obesity.predict(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 1: OLS REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# --- OBESITY MODEL ---\n",
    "print(\"\\n1. PREDICTING OBESITY RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_ols_obesity = LinearRegression()\n",
    "model_ols_obesity.fit(X_train, y_obesity_train)\n",
    "\n",
    "y_pred_train = model_ols_obesity.predict(X_train)\n",
    "y_pred_test = model_ols_obesity.predict(X_test)\n",
    "\n",
    "# Training metrics\n",
    "r2_train = r2_score(y_obesity_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_obesity_train, y_pred_train))\n",
    "mae_train = mean_absolute_error(y_obesity_train, y_pred_train)\n",
    "\n",
    "# Test metrics\n",
    "r2_test = r2_score(y_obesity_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_obesity_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_obesity_test, y_pred_test)\n",
    "\n",
    "print(f\"Training R²: {r2_train:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "# Store results\n",
    "results['OLS_Obesity'] = {\n",
    "    'model': model_ols_obesity,\n",
    "    'r2_train': r2_train,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test\n",
    "}\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nFeature Coefficients (Obesity):\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Coefficient': model_ols_obesity.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "# --- DIABETES MODEL ---\n",
    "print(\"\\n\\n2. PREDICTING DIABETES RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_ols_diabetes = LinearRegression()\n",
    "model_ols_diabetes.fit(X_train, y_diabetes_train)\n",
    "\n",
    "y_pred_train = model_ols_diabetes.predict(X_train)\n",
    "y_pred_test = model_ols_diabetes.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_diabetes_train, y_pred_train)\n",
    "r2_test = r2_score(y_diabetes_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_diabetes_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_diabetes_test, y_pred_test)\n",
    "\n",
    "print(f\"Training R²: {r2_train:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "results['OLS_Diabetes'] = {\n",
    "    'model': model_ols_diabetes,\n",
    "    'r2_train': r2_train,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test\n",
    "}\n",
    "\n",
    "print(\"\\nFeature Coefficients (Diabetes):\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Coefficient': model_ols_diabetes.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 2: Ridge Regression\n",
    "\n",
    "**Purpose:** Handle multicollinearity with L2 regularization  \n",
    "**Pros:** More stable than OLS, reduces overfitting  \n",
    "**Cons:** Requires tuning alpha parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 2: RIDGE REGRESSION (with Cross-Validation)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Alpha values to test\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "# --- OBESITY MODEL ---\n",
    "print(\"\\n1. PREDICTING OBESITY RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_ridge_obesity = RidgeCV(alphas=alphas, cv=5)\n",
    "model_ridge_obesity.fit(X_train, y_obesity_train)\n",
    "\n",
    "y_pred_test = model_ridge_obesity.predict(X_test)\n",
    "\n",
    "r2_test = r2_score(y_obesity_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_obesity_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_obesity_test, y_pred_test)\n",
    "\n",
    "print(f\"Best alpha: {model_ridge_obesity.alpha_}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "results['Ridge_Obesity'] = {\n",
    "    'model': model_ridge_obesity,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test,\n",
    "    'alpha': model_ridge_obesity.alpha_\n",
    "}\n",
    "\n",
    "# --- DIABETES MODEL ---\n",
    "print(\"\\n2. PREDICTING DIABETES RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_ridge_diabetes = RidgeCV(alphas=alphas, cv=5)\n",
    "model_ridge_diabetes.fit(X_train, y_diabetes_train)\n",
    "\n",
    "y_pred_test = model_ridge_diabetes.predict(X_test)\n",
    "\n",
    "r2_test = r2_score(y_diabetes_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_diabetes_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_diabetes_test, y_pred_test)\n",
    "\n",
    "print(f\"Best alpha: {model_ridge_diabetes.alpha_}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "results['Ridge_Diabetes'] = {\n",
    "    'model': model_ridge_diabetes,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test,\n",
    "    'alpha': model_ridge_diabetes.alpha_\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model 3: Lasso Regression\n",
    "\n",
    "**Purpose:** Feature selection with L1 regularization  \n",
    "**Pros:** Automatic feature selection, identifies important predictors  \n",
    "**Cons:** May eliminate useful correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 3: LASSO REGRESSION (with Cross-Validation)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- OBESITY MODEL ---\n",
    "print(\"\\n1. PREDICTING OBESITY RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_lasso_obesity = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "model_lasso_obesity.fit(X_train, y_obesity_train)\n",
    "\n",
    "y_pred_test = model_lasso_obesity.predict(X_test)\n",
    "\n",
    "r2_test = r2_score(y_obesity_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_obesity_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_obesity_test, y_pred_test)\n",
    "\n",
    "print(f\"Best alpha: {model_lasso_obesity.alpha_:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "# Selected features\n",
    "selected_features = [f for f, c in zip(available_features, model_lasso_obesity.coef_) if c != 0]\n",
    "print(f\"\\nFeatures selected: {len(selected_features)}/{len(available_features)}\")\n",
    "print(f\"Selected: {', '.join(selected_features)}\")\n",
    "\n",
    "results['Lasso_Obesity'] = {\n",
    "    'model': model_lasso_obesity,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test,\n",
    "    'alpha': model_lasso_obesity.alpha_,\n",
    "    'selected_features': selected_features\n",
    "}\n",
    "\n",
    "# --- DIABETES MODEL ---\n",
    "print(\"\\n2. PREDICTING DIABETES RATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "model_lasso_diabetes = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "model_lasso_diabetes.fit(X_train, y_diabetes_train)\n",
    "\n",
    "y_pred_test = model_lasso_diabetes.predict(X_test)\n",
    "\n",
    "r2_test = r2_score(y_diabetes_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_diabetes_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_diabetes_test, y_pred_test)\n",
    "\n",
    "print(f\"Best alpha: {model_lasso_diabetes.alpha_:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}%\")\n",
    "print(f\"Test MAE: {mae_test:.4f}%\")\n",
    "\n",
    "selected_features = [f for f, c in zip(available_features, model_lasso_diabetes.coef_) if c != 0]\n",
    "print(f\"\\nFeatures selected: {len(selected_features)}/{len(available_features)}\")\n",
    "print(f\"Selected: {', '.join(selected_features)}\")\n",
    "\n",
    "results['Lasso_Diabetes'] = {\n",
    "    'model': model_lasso_diabetes,\n",
    "    'r2_test': r2_test,\n",
    "    'rmse_test': rmse_test,\n",
    "    'mae_test': mae_test,\n",
    "    'alpha': model_lasso_diabetes.alpha_,\n",
    "    'selected_features': selected_features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for target in ['Obesity', 'Diabetes']:\n",
    "    for model_name in ['OLS', 'Ridge', 'Lasso']:\n",
    "        key = f\"{model_name}_{target}\"\n",
    "        if key in results:\n",
    "            comparison_data.append({\n",
    "                'Target': target,\n",
    "                'Model': model_name,\n",
    "                'R² Score': results[key]['r2_test'],\n",
    "                'RMSE': results[key]['rmse_test'],\n",
    "                'MAE': results[key]['mae_test']\n",
    "            })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "# Identify best models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODELS BY R² SCORE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for target in ['Obesity', 'Diabetes']:\n",
    "    target_df = comparison_df[comparison_df['Target'] == target]\n",
    "    best_model = target_df.loc[target_df['R² Score'].idxmax()]\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  Best Model: {best_model['Model']}\")\n",
    "    print(f\"  R² Score: {best_model['R² Score']:.4f}\")\n",
    "    print(f\"  RMSE: {best_model['RMSE']:.4f}%\")\n",
    "    print(f\"  MAE: {best_model['MAE']:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Analyze which features contribute most to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature importance from Ridge (best model typically)\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Obesity\ncoef_obesity = pd.DataFrame({\n    'Feature': available_features,\n    'Coefficient': model_ridge_obesity.coef_\n}).sort_values('Coefficient', key=abs, ascending=True)\n\ncolors_obesity = ['green' if x > 0 else 'red' for x in coef_obesity['Coefficient']]\naxes[0].barh(coef_obesity['Feature'], coef_obesity['Coefficient'], color=colors_obesity, alpha=0.7, edgecolor='black')\naxes[0].axvline(x=0, color='black', linewidth=1)\naxes[0].set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\naxes[0].set_title('Feature Importance: Obesity Prediction (Ridge)', fontsize=14, fontweight='bold')\naxes[0].grid(alpha=0.3, axis='x')\n\n# Diabetes\ncoef_diabetes = pd.DataFrame({\n    'Feature': available_features,\n    'Coefficient': model_ridge_diabetes.coef_\n}).sort_values('Coefficient', key=abs, ascending=True)\n\ncolors_diabetes = ['green' if x > 0 else 'red' for x in coef_diabetes['Coefficient']]\naxes[1].barh(coef_diabetes['Feature'], coef_diabetes['Coefficient'], color=colors_diabetes, alpha=0.7, edgecolor='black')\naxes[1].axvline(x=0, color='black', linewidth=1)\naxes[1].set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\naxes[1].set_title('Feature Importance: Diabetes Prediction (Ridge)', fontsize=14, fontweight='bold')\naxes[1].grid(alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.savefig('../data/output/feature_importance.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✓ Feature importance plot saved\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Actual vs Predicted plots\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Obesity\ny_pred_obesity = model_ridge_obesity.predict(X_test)\naxes[0].scatter(y_obesity_test, y_pred_obesity, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\naxes[0].plot([y_obesity_test.min(), y_obesity_test.max()], \n             [y_obesity_test.min(), y_obesity_test.max()], \n             'r--', linewidth=2, label='Perfect Prediction')\naxes[0].set_xlabel('Actual Obesity (%)', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Predicted Obesity (%)', fontsize=12, fontweight='bold')\naxes[0].set_title(f'Obesity Prediction (Ridge)\\nR² = {results[\"Ridge_Obesity\"][\"r2_test\"]:.4f}', \n                 fontsize=14, fontweight='bold')\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# Diabetes\ny_pred_diabetes = model_ridge_diabetes.predict(X_test)\naxes[1].scatter(y_diabetes_test, y_pred_diabetes, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\naxes[1].plot([y_diabetes_test.min(), y_diabetes_test.max()], \n             [y_diabetes_test.min(), y_diabetes_test.max()], \n             'r--', linewidth=2, label='Perfect Prediction')\naxes[1].set_xlabel('Actual Diabetes (%)', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Predicted Diabetes (%)', fontsize=12, fontweight='bold')\naxes[1].set_title(f'Diabetes Prediction (Ridge)\\nR² = {results[\"Ridge_Diabetes\"][\"r2_test\"]:.4f}', \n                 fontsize=14, fontweight='bold')\naxes[1].legend()\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('../data/output/prediction_accuracy.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✓ Prediction accuracy plot saved\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import joblib\n\n# Save best models\njoblib.dump(model_ridge_obesity, '../data/output/model_ridge_obesity.pkl')\njoblib.dump(model_ridge_diabetes, '../data/output/model_ridge_diabetes.pkl')\n\nprint(\"✓ Models saved:\")\nprint(\"  - model_ridge_obesity.pkl\")\nprint(\"  - model_ridge_diabetes.pkl\")\n\n# Save feature names\nfeature_info = {\n    'features': available_features,\n    'obesity_coef': model_ridge_obesity.coef_.tolist(),\n    'diabetes_coef': model_ridge_diabetes.coef_.tolist()\n}\n\nimport json\nwith open('../data/output/model_features.json', 'w') as f:\n    json.dump(feature_info, f, indent=2)\n\nprint(\"✓ Feature information saved\")\n\n# Save comparison results\ncomparison_df.to_csv('../data/output/model_comparison.csv', index=False)\nprint(\"✓ Comparison results saved\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS: REGRESSION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE:\")\n",
    "print(f\"   Obesity Prediction (Ridge): R² = {results['Ridge_Obesity']['r2_test']:.4f}\")\n",
    "print(f\"   Diabetes Prediction (Ridge): R² = {results['Ridge_Diabetes']['r2_test']:.4f}\")\n",
    "\n",
    "print(\"\\n2. FOOD ACCESS BARRIER INDEX CONTRIBUTION:\")\n",
    "fab_coef_obesity = model_ridge_obesity.coef_[available_features.index('Food_Access_Barrier_Index')]\n",
    "fab_coef_diabetes = model_ridge_diabetes.coef_[available_features.index('Food_Access_Barrier_Index')]\n",
    "print(f\"   Obesity: {fab_coef_obesity:.4f} (rank #{coef_obesity['Feature'].tolist().index('Food_Access_Barrier_Index')+1})\")\n",
    "print(f\"   Diabetes: {fab_coef_diabetes:.4f} (rank #{coef_diabetes['Feature'].tolist().index('Food_Access_Barrier_Index')+1})\")\n",
    "\n",
    "print(\"\\n3. TOP 3 PREDICTORS:\")\n",
    "print(\"\\n   Obesity:\")\n",
    "for i, (feat, coef) in enumerate(coef_obesity.tail(3).values[::-1], 1):\n",
    "    print(f\"     {i}. {feat}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\n   Diabetes:\")\n",
    "for i, (feat, coef) in enumerate(coef_diabetes.tail(3).values[::-1], 1):\n",
    "    print(f\"     {i}. {feat}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\n4. ANSWER TO YOUR QUESTION:\")\n",
    "print(\"   Is Food_Access_Barrier_Index a good predictor?\")\n",
    "print(f\"   • For DIABETES: YES (strong contributor, coef={fab_coef_diabetes:.4f})\")\n",
    "print(f\"   • For OBESITY: MODERATE (coef={fab_coef_obesity:.4f})\")\n",
    "print(\"   • Socioeconomic factors and education are stronger predictors\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}